{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# library importing"
      ],
      "metadata": {
        "id": "t6GB-fUCNIC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UTChxDW4Mx9h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "# import dis\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "import platform\n",
        "import statistics\n",
        "import subprocess\n",
        "# import requests\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import copy\n",
        "import inspect\n",
        "import importlib.util\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Callable, Any, Optional, List\n",
        "from types import MappingProxyType, FunctionType\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from composite_score_calculator import CompositeScoreCalculator\n",
        "from instruction_cost_model import InstructionCostModel\n",
        "from enhanced_cost_analyzer import EnhancedCostAnalyzer\n",
        "from reporting import create_repository_comparison_chart, DEFAULT_REPORT_DIR\n",
        "from utils import utils as u"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# constants"
      ],
      "metadata": {
        "id": "hfAh1VlUmwW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_configuration(config_file: str = DEFAULT_CONFIG_WEIGHTS_PATH) -> tuple:\n",
        "    \"\"\"\n",
        "    Loads configuration from JSON file and creates constant dictionaries.\n",
        "\n",
        "    Args:\n",
        "        config_file: Path to configuration file\n",
        "\n",
        "    Returns:\n",
        "        tuple: Tuple with all constant dictionaries\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(config_file, 'r', encoding='utf-8') as f:\n",
        "            config_data = json.load(f)\n",
        "\n",
        "        # Extract weight profiles (using 'weights' subkey if structured format)\n",
        "        weight_profiles = config_data['weight_profiles']\n",
        "\n",
        "        # Handle both simple and structured formats\n",
        "        def extract_weights(profile_data):\n",
        "            if isinstance(profile_data, dict) and 'weights' in profile_data:\n",
        "                return profile_data['weights']\n",
        "            return profile_data\n",
        "\n",
        "        # Create constants for weight profiles\n",
        "        DEFAULT_COMPOSITE_WEIGHTS = extract_weights(weight_profiles['default_composite'])\n",
        "        RESEARCH_WEIGHTS = extract_weights(weight_profiles['research'])\n",
        "        COMMERCIAL_WEIGHTS = extract_weights(weight_profiles['commercial'])\n",
        "        MOBILE_WEIGHTS = extract_weights(weight_profiles['mobile'])\n",
        "        HPC_WEIGHTS = extract_weights(weight_profiles['hpc'])\n",
        "\n",
        "        # Handle reference values\n",
        "        reference_data = config_data['reference_values']\n",
        "        if 'values' in reference_data:\n",
        "            REFERENCE_VALUES = reference_data['values']\n",
        "        else:\n",
        "            REFERENCE_VALUES = reference_data\n",
        "\n",
        "        return (\n",
        "            DEFAULT_COMPOSITE_WEIGHTS,\n",
        "            RESEARCH_WEIGHTS,\n",
        "            COMMERCIAL_WEIGHTS,\n",
        "            MOBILE_WEIGHTS,\n",
        "            HPC_WEIGHTS,\n",
        "            REFERENCE_VALUES\n",
        "        )\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Configuration file '{config_file}' not found\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"Invalid JSON format in configuration file: {e}\")\n",
        "    except KeyError as e:\n",
        "        raise KeyError(f\"Missing required configuration key: {e}\")\n",
        "\n",
        "\n",
        "# Alternative approach with class for encapsulation\n",
        "class WeightConfiguration:\n",
        "    \"\"\"Class for managing weight coefficient configuration.\"\"\"\n",
        "\n",
        "    def __init__(self, config_file: str = DEFAULT_CONFIG_WEIGHTS_PATH):\n",
        "        self._load_config(config_file)\n",
        "\n",
        "    def _load_config(self, config_file: str) -> None:\n",
        "        \"\"\"Loads configuration from file.\"\"\"\n",
        "        with open(config_file, 'r', encoding='utf-8') as f:\n",
        "            config_data = json.load(f)\n",
        "\n",
        "        # Create class attributes\n",
        "        profiles = config_data['weight_profiles']\n",
        "        self.DEFAULT_COMPOSITE_WEIGHTS = profiles['default_composite']\n",
        "        self.RESEARCH_WEIGHTS = profiles['research']\n",
        "        self.COMMERCIAL_WEIGHTS = profiles['commercial']\n",
        "        self.MOBILE_WEIGHTS = profiles['mobile']\n",
        "        self.HPC_WEIGHTS = profiles['hpc']\n",
        "        self.REFERENCE_VALUES = config_data['reference_values']\n",
        "\n",
        "    def get_profile(self, profile_name: str) -> Dict[str, float]:\n",
        "        \"\"\"Returns weight profile by name.\"\"\"\n",
        "        profile_mapping = {\n",
        "            'default_composite': self.DEFAULT_COMPOSITE_WEIGHTS,\n",
        "            'research': self.RESEARCH_WEIGHTS,\n",
        "            'commercial': self.COMMERCIAL_WEIGHTS,\n",
        "            'mobile': self.MOBILE_WEIGHTS,\n",
        "            'hpc': self.HPC_WEIGHTS\n",
        "        }\n",
        "\n",
        "        if profile_name not in profile_mapping:\n",
        "            raise ValueError(f\"Unknown profile: {profile_name}\")\n",
        "\n",
        "        return profile_mapping[profile_name]\n",
        "\n",
        "    def validate_weights(self, weights: Dict[str, float]) -> bool:\n",
        "        \"\"\"Validates that weight sum equals 1.0 and all keys are present.\"\"\"\n",
        "        required_keys = {'CU', 'EU', 'CO2', '$'}\n",
        "\n",
        "        if set(weights.keys()) != required_keys:\n",
        "            return False\n",
        "\n",
        "        total_weight = sum(weights.values())\n",
        "        return abs(total_weight - 1.0) < 1e-10"
      ],
      "metadata": {
        "id": "pRhWvWp4QkPG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CARBON_INTENSITY_API = \"https://api.carbonintensity.org.uk/intensity\"\n",
        "# DEFAULT_CARBON_INTENSITY = 0.2  # Fallback value in kgCO2/kWh\n",
        "# DEFAULT_COST_MODEL_PATH = \"./cost_models\"\n",
        "DEFAULT_EXAMPLES_PATH = \"./examples\"\n",
        "SAVING_FLAG = True\n",
        "# CHECKING_WEIGHTS_FLAG = False\n",
        "# DEFAULT_REPORT_DIR = \"./enhanced_reports\"\n",
        "# DEFAULT_CONFIG_WEIGHTS_PATH = DEFAULT_COST_MODEL_PATH + '/config_weights.json'\n",
        "\n",
        "# (DEFAULT_COMPOSITE_WEIGHTS, RESEARCH_WEIGHTS, COMMERCIAL_WEIGHTS,\n",
        "#   MOBILE_WEIGHTS, HPC_WEIGHTS, REFERENCE_VALUES) = load_configuration()\n",
        "\n",
        "# PROFILE_WEIGHTS = MappingProxyType({\n",
        "#     \"RESEARCH\": RESEARCH_WEIGHTS,\n",
        "#     \"COMMERCIAL\": COMMERCIAL_WEIGHTS,\n",
        "#     \"MOBILE\": MOBILE_WEIGHTS,\n",
        "#     \"HPC\": HPC_WEIGHTS,\n",
        "#     \"DEFAULT\": DEFAULT_COMPOSITE_WEIGHTS,\n",
        "# })\n",
        "\n",
        "# if CHECKING_WEIGHTS_FLAG:\n",
        "#   # usage by class\n",
        "#   config = WeightConfiguration()\n",
        "#   research_profile = config.get_profile('research')\n",
        "#   print(f\"Research profile: {research_profile}\")\n",
        "\n",
        "#   # validation\n",
        "#   is_valid = config.validate_weights(config.RESEARCH_WEIGHTS)\n",
        "#   print(f\"Research weights valid: {is_valid}\")\n",
        "\n",
        "\n",
        "# def process_zip_file(zip_filename, target_directory):\n",
        "#     \"\"\"\n",
        "#     Unzips a zip file to the specified directory and deletes the archive\n",
        "#     \"\"\"\n",
        "#     zip_path = f'./{zip_filename}'\n",
        "\n",
        "#     if not os.path.exists(zip_path):\n",
        "#         print(f\"Error: file {zip_path} not found!\")\n",
        "#         return False\n",
        "\n",
        "#     os.makedirs(target_directory, exist_ok=True)\n",
        "\n",
        "#     try:\n",
        "#         with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#             print(f\"Extracting {zip_filename}...\")\n",
        "\n",
        "#             file_list = zip_ref.namelist()\n",
        "#             print(f\"Files found in archive: {len(file_list)}\")\n",
        "\n",
        "#             zip_ref.extractall(target_directory)\n",
        "\n",
        "#             for file_name in file_list:\n",
        "#                 extracted_path = os.path.join(target_directory, file_name)\n",
        "#                 if os.path.isfile(extracted_path):\n",
        "#                     file_size = os.path.getsize(extracted_path)\n",
        "#                     print(f\"Exctracted: {file_name} ({file_size} byte)\")\n",
        "\n",
        "#         os.remove(zip_path)\n",
        "#         print(f\"Zip-file {zip_filename} has been deleted\")\n",
        "\n",
        "#         print(f\"Operation completed successfully! Files saved in: {target_directory}\")\n",
        "#         return True\n",
        "\n",
        "#     except zipfile.BadZipFile:\n",
        "#         print(f\"Erroe: {zip_filename} is corrupted or is not a zip file\")\n",
        "#         return False\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error while processing: {str(e)}\")\n",
        "#         return False\n",
        "\n",
        "\n",
        "os.makedirs(DEFAULT_COST_MODEL_PATH[2:], exist_ok=True)\n",
        "os.makedirs(DEFAULT_EXAMPLES_PATH[2:], exist_ok=True)\n",
        "zip_filename_models = \"cost_models.zip\"\n",
        "zip_filename_examples = \"examples.zip\"\n",
        "\n",
        "u.process_zip_file(zip_filename_models, DEFAULT_COST_MODEL_PATH)\n",
        "u.process_zip_file(zip_filename_examples, DEFAULT_EXAMPLES_PATH)"
      ],
      "metadata": {
        "id": "FDiokNQQmzhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3841c84b-9fcc-47de-c276-a82cfb924607"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: file ./cost_models.zip not found!\n",
            "Error: file ./examples.zip not found!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://example.com/file.zip"
      ],
      "metadata": {
        "id": "iZejS-MuPfIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# needed functions and classes"
      ],
      "metadata": {
        "id": "xIXLbcAjNw3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CompositeScoreCalculator:\n",
        "    \"\"\"\n",
        "    Calculator for unified composite scores based on multiple cost metrics.\n",
        "\n",
        "    Provides normalization, scaling, and weighted combination of cost metrics\n",
        "    into a single composite score for algorithm comparison.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 weights: Optional[Dict[str, float]] = None,\n",
        "                 profile: str = \"DEFAULT\",\n",
        "                 reference_values: Optional[Dict[str, Dict[str, float]]] = None):\n",
        "        \"\"\"\n",
        "        Initialize composite score calculator.\n",
        "\n",
        "        Args:\n",
        "            weights: Weight distribution for metrics (must sum to 1.0)\n",
        "            profile: Predefined profile name ('HPC', 'MOBILE', 'COMMERCIAL', 'RESEARCH', 'DEFAULT')\n",
        "            reference_values: Reference values for normalization\n",
        "        \"\"\"\n",
        "        self.profile = profile\n",
        "\n",
        "        if weights is not None:\n",
        "            self.weights = dict(weights)\n",
        "        elif profile is not None:\n",
        "            if profile not in PROFILE_WEIGHTS:\n",
        "                raise ValueError(f\"Unknown profile: {profile}. Available: {list(PROFILE_WEIGHTS.keys())}\")\n",
        "            self.weights = PROFILE_WEIGHTS[profile].copy()\n",
        "        else:\n",
        "            self.weights = DEFAULT_COMPOSITE_WEIGHTS.copy()\n",
        "\n",
        "        self.reference_values = copy.deepcopy(reference_values) if reference_values else copy.deepcopy(REFERENCE_VALUES)\n",
        "\n",
        "        # Validate weights sum to 1.0\n",
        "        weight_sum = sum(self.weights.values())\n",
        "        if abs(weight_sum - 1.0) > 1e-6:\n",
        "            raise ValueError(f\"Weights must sum to 1.0, got {weight_sum}\")\n",
        "\n",
        "    def normalize_metric(self, value: float, metric: str, method: str = \"minmax\") -> float:\n",
        "        \"\"\"\n",
        "        Normalize a metric value to 0-100 scale.\n",
        "\n",
        "        Args:\n",
        "            value: Raw metric value\n",
        "            metric: Metric name (CU, EU, CO2, $)\n",
        "            method: Normalization method ('minmax', 'zscore', 'log')\n",
        "\n",
        "        Returns:\n",
        "            Normalized score (0-100)\n",
        "        \"\"\"\n",
        "        if metric not in self.reference_values:\n",
        "            return 50.0  # Default middle value for unknown metrics\n",
        "\n",
        "        ref = self.reference_values[metric]\n",
        "        min_val, max_val = ref[\"min\"], ref[\"max\"]\n",
        "\n",
        "        if method == \"minmax\":\n",
        "            # Min-max normalization with inversion (lower is better)\n",
        "            if max_val <= min_val:\n",
        "                return 50.0\n",
        "            normalized = (value - min_val) / (max_val - min_val)\n",
        "            # Invert: lower cost = higher score\n",
        "            return max(0.0, min(100.0, 100.0 * (1.0 - normalized)))\n",
        "\n",
        "        elif method == \"zscore\":\n",
        "            # Z-score normalization using typical value as mean\n",
        "            typical = ref[\"typical\"]\n",
        "            std_estimate = (max_val - min_val) / 6  # Rough 6-sigma estimate\n",
        "            if std_estimate <= 0:\n",
        "                return 50.0\n",
        "            z_score = (value - typical) / std_estimate\n",
        "            # Convert to percentile and invert\n",
        "            percentile = self._z_to_percentile(-z_score)  # Negative for inversion\n",
        "            return max(0.0, min(100.0, percentile))\n",
        "\n",
        "        elif method == \"log\":\n",
        "            # Logarithmic normalization for highly skewed data\n",
        "            if value <= 0 or min_val <= 0 or max_val <= min_val:\n",
        "                return 50.0\n",
        "            log_val = math.log(value)\n",
        "            log_min = math.log(min_val)\n",
        "            log_max = math.log(max_val)\n",
        "            normalized = (log_val - log_min) / (log_max - log_min)\n",
        "            return max(0.0, min(100.0, 100.0 * (1.0 - normalized)))\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown normalization method: {method}\")\n",
        "\n",
        "    def _z_to_percentile(self, z_score: float) -> float:\n",
        "        \"\"\"Convert z-score to percentile using approximation.\"\"\"\n",
        "        # Approximation of cumulative normal distribution\n",
        "        return 50.0 * (1.0 + math.erf(z_score / math.sqrt(2)))\n",
        "\n",
        "    def calculate_composite_score(self, metrics: Dict[str, float],\n",
        "                                method: str = \"minmax\") -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Calculate composite score from individual metrics.\n",
        "\n",
        "        Args:\n",
        "            metrics: Dictionary with raw metric values\n",
        "            method: Normalization method to use\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with normalized scores and composite score\n",
        "        \"\"\"\n",
        "        normalized_scores = {}\n",
        "\n",
        "        # Normalize each metric\n",
        "        for metric, value in metrics.items():\n",
        "            if metric in self.weights:\n",
        "                normalized_scores[f\"{metric}_normalized\"] = self.normalize_metric(\n",
        "                    value, metric, method\n",
        "                )\n",
        "\n",
        "        # Calculate weighted composite score\n",
        "        composite_score = 0.0\n",
        "        for metric, weight in self.weights.items():\n",
        "            normalized_key = f\"{metric}_normalized\"\n",
        "            if normalized_key in normalized_scores:\n",
        "                composite_score += weight * normalized_scores[normalized_key]\n",
        "\n",
        "        # Add composite score to results\n",
        "        result = metrics.copy()\n",
        "        result.update(normalized_scores)\n",
        "        result[\"COMPOSITE_SCORE\"] = composite_score\n",
        "\n",
        "        # Add score interpretation\n",
        "        result[\"SCORE_GRADE\"] = self._get_score_grade(composite_score)\n",
        "        result[\"EFFICIENCY_RATING\"] = self._get_efficiency_rating(composite_score)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _get_score_grade(self, score: float) -> str:\n",
        "        \"\"\"Convert numeric score to letter grade.\"\"\"\n",
        "        if score >= 90: return \"A+\"\n",
        "        elif score >= 85: return \"A\"\n",
        "        elif score >= 80: return \"A-\"\n",
        "        elif score >= 75: return \"B+\"\n",
        "        elif score >= 70: return \"B\"\n",
        "        elif score >= 65: return \"B-\"\n",
        "        elif score >= 60: return \"C+\"\n",
        "        elif score >= 55: return \"C\"\n",
        "        elif score >= 50: return \"C-\"\n",
        "        elif score >= 40: return \"D\"\n",
        "        else: return \"F\"\n",
        "\n",
        "    def _get_efficiency_rating(self, score: float) -> str:\n",
        "        \"\"\"Convert numeric score to efficiency rating.\"\"\"\n",
        "        if score >= 85: return \"Excellent\"\n",
        "        elif score >= 70: return \"Good\"\n",
        "        elif score >= 55: return \"Average\"\n",
        "        elif score >= 40: return \"Below Average\"\n",
        "        else: return \"Poor\"\n",
        "\n",
        "    def update_reference_values(self, benchmark_results: List[Dict[str, float]]) -> None:\n",
        "        \"\"\"\n",
        "        Update reference values based on benchmark results.\n",
        "\n",
        "        Args:\n",
        "            benchmark_results: List of metric dictionaries from benchmark runs\n",
        "        \"\"\"\n",
        "        if not benchmark_results:\n",
        "            return\n",
        "\n",
        "        for metric in self.weights.keys():\n",
        "            values = [result.get(metric, 0) for result in benchmark_results if metric in result]\n",
        "            if values:\n",
        "                self.reference_values[metric] = {\n",
        "                    \"min\": min(values),\n",
        "                    \"max\": max(values),\n",
        "                    \"typical\": statistics.median(values)\n",
        "                }\n",
        "\n",
        "    def get_profile_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get information about current weight profile.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with profile information\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"profile\": self.profile,\n",
        "            \"weights\": self.weights.copy(),\n",
        "            \"description\": self._get_profile_description()\n",
        "        }\n",
        "\n",
        "    def _get_profile_description(self) -> str:\n",
        "        \"\"\"Get description of current profile.\"\"\"\n",
        "        descriptions = {\n",
        "            \"HPC\": \"High Performance Computing - optimized for maximum computational throughput\",\n",
        "            \"MOBILE\": \"Mobile/IoT - optimized for energy efficiency and battery life\",\n",
        "            \"COMMERCIAL\": \"Commercial Cloud - balanced approach with cost consideration\",\n",
        "            \"RESEARCH\": \"Research/Academic - focused on performance with environmental awareness\",\n",
        "            \"DEFAULT\": \"Default balanced profile for general use cases\",\n",
        "            \"CUSTOM\": \"Custom weight configuration\"\n",
        "        }\n",
        "        return descriptions.get(self.profile, \"Custom profile configuration\")\n",
        "\n",
        "\n",
        "class InstructionCostModel:\n",
        "    \"\"\"\n",
        "    Model for instruction costs across different architectures.\n",
        "\n",
        "    Loads cost models from JSON files and provides cost lookup functionality\n",
        "    for different instruction types across various metrics (CU, EU, CO2, $).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, arch: str) -> None:\n",
        "        \"\"\"\n",
        "        Initialize instruction cost model for specified architecture.\n",
        "\n",
        "        Args:\n",
        "            arch: Target architecture (e.g., 'x86_64', 'arm', 'gpu')\n",
        "\n",
        "        Raises:\n",
        "            RuntimeError: If cost model file for architecture is not found\n",
        "        \"\"\"\n",
        "        self.arch = arch.lower()\n",
        "        self.weights = self._load_weights()\n",
        "        self.bytecode_mapping = self._get_bytecode_mapping()\n",
        "\n",
        "    def _load_weights(self) -> Dict[str, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Load instruction weights from architecture-specific JSON file.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping instruction names to cost metrics\n",
        "\n",
        "        Raises:\n",
        "            RuntimeError: If cost model file cannot be loaded\n",
        "        \"\"\"\n",
        "        # Try multiple ways to find the correct path\n",
        "        possible_paths = []\n",
        "\n",
        "        # Method 1: Use __file__ if available\n",
        "        try:\n",
        "            script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "            possible_paths.append(os.path.join(script_dir, f\"cost_models/{self.arch}_instr_costs.json\"))\n",
        "        except NameError:\n",
        "            pass\n",
        "\n",
        "        # Method 2: Current working directory\n",
        "        possible_paths.append(f\"cost_models/{self.arch}_instr_costs.json\")\n",
        "\n",
        "        # Method 3: Relative to current directory\n",
        "        possible_paths.append(f\"./{self.arch}_instr_costs.json\")\n",
        "\n",
        "        # Method 4: Check if DEFAULT_COST_MODEL_PATH exists\n",
        "        if os.path.exists(DEFAULT_COST_MODEL_PATH):\n",
        "            possible_paths.append(\n",
        "                os.path.join(DEFAULT_COST_MODEL_PATH, f\"{self.arch}_instr_costs.json\")\n",
        "            )\n",
        "\n",
        "        # Try each path until one works\n",
        "        for model_file in possible_paths:\n",
        "            try:\n",
        "                if os.path.exists(model_file):\n",
        "                    with open(model_file, 'r', encoding='utf-8') as f:\n",
        "                        return json.load(f)\n",
        "            except (FileNotFoundError, json.JSONDecodeError, PermissionError):\n",
        "                continue\n",
        "\n",
        "        # If no file found, use default fallback model\n",
        "        print(f\"Warning: Cost model not found for architecture: {self.arch}. Using default values.\")\n",
        "        return self._get_default_cost_model()\n",
        "\n",
        "    def _get_default_cost_model(self) -> Dict[str, Dict[str, float]]:\n",
        "        \"\"\"Get default cost model when no file is available.\"\"\"\n",
        "        return {\n",
        "            \"ADD\": {\"CU\": 1.0, \"EU\": 0.0001, \"CO2\": 0.00005, \"$\": 0.00001},\n",
        "            \"SUB\": {\"CU\": 1.0, \"EU\": 0.0001, \"CO2\": 0.00005, \"$\": 0.00001},\n",
        "            \"MUL\": {\"CU\": 3.0, \"EU\": 0.0003, \"CO2\": 0.00015, \"$\": 0.00003},\n",
        "            \"DIV\": {\"CU\": 10.0, \"EU\": 0.001, \"CO2\": 0.0005, \"$\": 0.0001},\n",
        "            \"LOAD\": {\"CU\": 2.0, \"EU\": 0.0002, \"CO2\": 0.0001, \"$\": 0.00002},\n",
        "            \"STORE\": {\"CU\": 2.0, \"EU\": 0.0002, \"CO2\": 0.0001, \"$\": 0.00002},\n",
        "            \"JMP\": {\"CU\": 1.5, \"EU\": 0.00015, \"CO2\": 0.000075, \"$\": 0.000015},\n",
        "            \"CALL\": {\"CU\": 5.0, \"EU\": 0.0005, \"CO2\": 0.00025, \"$\": 0.00005},\n",
        "            \"MOV\": {\"CU\": 1.0, \"EU\": 0.0001, \"CO2\": 0.00005, \"$\": 0.00001},\n",
        "            \"AND\": {\"CU\": 1.0, \"EU\": 0.0001, \"CO2\": 0.00005, \"$\": 0.00001},\n",
        "            \"OR\": {\"CU\": 1.0, \"EU\": 0.0001, \"CO2\": 0.00005, \"$\": 0.00001},\n",
        "            \"XOR\": {\"CU\": 1.0, \"EU\": 0.0001, \"CO2\": 0.00005, \"$\": 0.00001}\n",
        "        }\n",
        "\n",
        "    def _get_bytecode_mapping(self) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Get mapping from Python bytecode instructions to architecture instructions.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping bytecode ops to architecture ops\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'BINARY_ADD': 'ADD',\n",
        "            'BINARY_SUBTRACT': 'SUB',\n",
        "            'BINARY_MULTIPLY': 'MUL',\n",
        "            'BINARY_TRUE_DIVIDE': 'DIV',\n",
        "            'BINARY_FLOOR_DIVIDE': 'DIV',\n",
        "            'BINARY_AND': 'AND',\n",
        "            'BINARY_OR': 'OR',\n",
        "            'BINARY_XOR': 'XOR',\n",
        "            'LOAD_CONST': 'LOAD',\n",
        "            'LOAD_FAST': 'LOAD',\n",
        "            'LOAD_GLOBAL': 'LOAD',\n",
        "            'STORE_FAST': 'STORE',\n",
        "            'STORE_GLOBAL': 'STORE',\n",
        "            'STORE_NAME': 'STORE',\n",
        "            'JUMP_FORWARD': 'JMP',\n",
        "            'JUMP_IF_TRUE_OR_POP': 'JMP',\n",
        "            'JUMP_IF_FALSE_OR_POP': 'JMP',\n",
        "            'CALL_FUNCTION': 'CALL',\n",
        "            'RETURN_VALUE': 'MOV'\n",
        "        }\n",
        "\n",
        "    def get_cost(self, opname: str, is_bytecode: bool = False) -> Tuple[float, float, float, float]:\n",
        "        \"\"\"\n",
        "        Get cost metrics for specified instruction.\n",
        "\n",
        "        Args:\n",
        "            opname: Instruction operation name\n",
        "            is_bytecode: Whether the opname is Python bytecode instruction\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (CU, EU, CO2, $) cost values\n",
        "        \"\"\"\n",
        "        opname = opname.upper()\n",
        "\n",
        "        # Map Python bytecode to architecture instruction if needed\n",
        "        if is_bytecode and opname in self.bytecode_mapping:\n",
        "            opname = self.bytecode_mapping[opname]\n",
        "\n",
        "        data = self.weights.get(opname)\n",
        "\n",
        "        if data is None:\n",
        "            # Default fallback values for unknown instructions\n",
        "            default_values = {\n",
        "                \"CU\": 1.0,\n",
        "                \"EU\": 0.0001,\n",
        "                \"CO2\": 0.00005,\n",
        "                \"$\": 0.00001\n",
        "            }\n",
        "            return (\n",
        "                default_values[\"CU\"],\n",
        "                default_values[\"EU\"],\n",
        "                default_values[\"CO2\"],\n",
        "                default_values[\"$\"]\n",
        "            )\n",
        "\n",
        "        # Extract only the required metrics, ignoring extra fields\n",
        "        return (\n",
        "            data.get(\"CU\", 1.0),\n",
        "            data.get(\"EU\", 0.0001),\n",
        "            data.get(\"CO2\", 0.00005),\n",
        "            data.get(\"$\", 0.00001)\n",
        "        )\n",
        "\n",
        "\n",
        "class EnhancedCostAnalyzer:\n",
        "    \"\"\"\n",
        "    Enhanced analyzer class for evaluating algorithm costs with composite scoring.\n",
        "\n",
        "    Provides methods to analyze Python functions, LLVM IR, and PTX code\n",
        "    to estimate computational costs across multiple metrics, including\n",
        "    unified composite scores for algorithm comparison.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, arch: str = \"x86_64\",\n",
        "                 composite_weights: Optional[Dict[str, float]] = None,\n",
        "                 profile: str = \"DEFAULT\") -> None:\n",
        "        \"\"\"\n",
        "        Initialize enhanced cost analyzer with specified architecture.\n",
        "\n",
        "        Args:\n",
        "            arch: Target architecture for cost model\n",
        "            composite_weights: Custom weights for composite score calculation\n",
        "            profile: Predefined profile name ('HPC', 'MOBILE', 'COMMERCIAL', 'RESEARCH', 'DEFAULT')\n",
        "        \"\"\"\n",
        "        self.arch = arch\n",
        "        self.profile = profile\n",
        "        self.weights = copy.deepcopy(composite_weights) if composite_weights \\\n",
        "                       else copy.deepcopy(PROFILE_WEIGHTS.get(profile, DEFAULT_COMPOSITE_WEIGHTS))\n",
        "        self.model = InstructionCostModel(arch=arch)\n",
        "        self.composite_calculator = CompositeScoreCalculator(\n",
        "            weights=self.weights,\n",
        "            profile=profile\n",
        "        )\n",
        "        self.benchmark_history = []\n",
        "\n",
        "    def analyze_function(self, fn: Callable[..., Any],\n",
        "                        include_composite: bool = True) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Analyze Python function bytecode and calculate costs with composite score.\n",
        "\n",
        "        Args:\n",
        "            fn: Python function to analyze\n",
        "            include_composite: Whether to calculate composite score\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with cost metrics and composite score\n",
        "        \"\"\"\n",
        "        instructions = list(dis.get_instructions(fn))\n",
        "        summary = {\"CU\": 0.0, \"EU\": 0.0, \"CO2\": 0.0, \"$\": 0.0}\n",
        "\n",
        "        for instr in instructions:\n",
        "            cu, eu, co2, money = self.model.get_cost(instr.opname, is_bytecode=True)\n",
        "            summary[\"CU\"] += cu\n",
        "            summary[\"EU\"] += eu\n",
        "            summary[\"CO2\"] += co2\n",
        "            summary[\"$\"] += money\n",
        "\n",
        "        if include_composite:\n",
        "            summary = self.composite_calculator.calculate_composite_score(summary)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def analyze_llvm_ir(self, ir_path: str, include_composite: bool = True) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Analyze LLVM IR file and calculate costs with composite score.\n",
        "\n",
        "        Args:\n",
        "            ir_path: Path to LLVM IR file (.ll)\n",
        "            include_composite: Whether to calculate composite score\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with cost metrics and composite score\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If IR file cannot be found\n",
        "        \"\"\"\n",
        "        summary = {\"CU\": 0.0, \"EU\": 0.0, \"CO2\": 0.0, \"$\": 0.0}\n",
        "\n",
        "        with open(ir_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line or line.startswith(';'):\n",
        "                    continue\n",
        "\n",
        "                tokens = line.split()\n",
        "                if tokens:\n",
        "                    # Find actual instruction (skip assignments like %1 =)\n",
        "                    opcode = None\n",
        "                    for token in tokens:\n",
        "                        if '=' not in token and not token.startswith('%'):\n",
        "                            opcode = token.upper()\n",
        "                            break\n",
        "\n",
        "                    if opcode:\n",
        "                        cu, eu, co2, money = self.model.get_cost(opcode)\n",
        "                        summary[\"CU\"] += cu\n",
        "                        summary[\"EU\"] += eu\n",
        "                        summary[\"CO2\"] += co2\n",
        "                        summary[\"$\"] += money\n",
        "\n",
        "        if include_composite:\n",
        "            summary = self.composite_calculator.calculate_composite_score(summary)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def analyze_ptx(self, ptx_path: str, include_composite: bool = True) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Analyze PTX (Parallel Thread Execution) file and calculate costs with composite score.\n",
        "\n",
        "        Args:\n",
        "            ptx_path: Path to PTX file (.ptx)\n",
        "            include_composite: Whether to calculate composite score\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with cost metrics and composite score\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If PTX file cannot be found\n",
        "        \"\"\"\n",
        "        summary = {\"CU\": 0.0, \"EU\": 0.0, \"CO2\": 0.0, \"$\": 0.0}\n",
        "\n",
        "        with open(ptx_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if (not line or line.startswith(';') or line.startswith('//') or\n",
        "                    line.startswith('.') or line.startswith('{')):\n",
        "                    continue\n",
        "\n",
        "                tokens = line.split()\n",
        "                if tokens:\n",
        "                    instr = tokens[0].upper().rstrip(':')\n",
        "                    # Skip labels and directives\n",
        "                    if not instr.endswith(':') and not instr.startswith('.'):\n",
        "                        cu, eu, co2, money = self.model.get_cost(instr)\n",
        "                        summary[\"CU\"] += cu\n",
        "                        summary[\"EU\"] += eu\n",
        "                        summary[\"CO2\"] += co2\n",
        "                        summary[\"$\"] += money\n",
        "\n",
        "        if include_composite:\n",
        "            summary = self.composite_calculator.calculate_composite_score(summary)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def fetch_carbon_intensity(self) -> float:\n",
        "        \"\"\"\n",
        "        Fetch current carbon intensity from external API.\n",
        "\n",
        "        Returns:\n",
        "            Carbon intensity in kgCO2/kWh, or fallback value if API unavailable\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = requests.get(CARBON_INTENSITY_API, timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                # Convert gCO2 to kgCO2\n",
        "                return data[\"data\"][0][\"intensity\"][\"actual\"] / 1000.0\n",
        "        except (requests.RequestException, KeyError, IndexError):\n",
        "            pass\n",
        "\n",
        "        return DEFAULT_CARBON_INTENSITY\n",
        "\n",
        "    def compare_functions(\n",
        "        self,\n",
        "        fn_old: Callable[..., Any],\n",
        "        fn_new: Callable[..., Any],\n",
        "        include_composite: bool = True\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Compare costs between two functions (differential analysis) with composite scores.\n",
        "\n",
        "        Args:\n",
        "            fn_old: Original function\n",
        "            fn_new: New function to compare against\n",
        "            include_composite: Whether to include composite score analysis\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with detailed comparison results\n",
        "        \"\"\"\n",
        "        old_cost = self.analyze_function(fn_old, include_composite)\n",
        "        new_cost = self.analyze_function(fn_new, include_composite)\n",
        "\n",
        "        # Calculate raw differences\n",
        "        differences = {}\n",
        "        for key in [\"CU\", \"EU\", \"CO2\", \"$\"]:\n",
        "            differences[f\"{key}_diff\"] = new_cost[key] - old_cost[key]\n",
        "            differences[f\"{key}_ratio\"] = (new_cost[key] / old_cost[key]) if old_cost[key] > 0 else float('inf')\n",
        "            differences[f\"{key}_percent_change\"] = (\n",
        "                ((new_cost[key] - old_cost[key]) / old_cost[key]) * 100\n",
        "                if old_cost[key] > 0 else float('inf')\n",
        "            )\n",
        "\n",
        "        # Composite score comparison\n",
        "        if include_composite:\n",
        "            differences[\"COMPOSITE_SCORE_diff\"] = (\n",
        "                new_cost[\"COMPOSITE_SCORE\"] - old_cost[\"COMPOSITE_SCORE\"]\n",
        "            )\n",
        "            differences[\"improvement\"] = new_cost[\"COMPOSITE_SCORE\"] > old_cost[\"COMPOSITE_SCORE\"]\n",
        "            differences[\"old_grade\"] = old_cost[\"SCORE_GRADE\"]\n",
        "            differences[\"new_grade\"] = new_cost[\"SCORE_GRADE\"]\n",
        "\n",
        "        return {\n",
        "            \"old_metrics\": old_cost,\n",
        "            \"new_metrics\": new_cost,\n",
        "            \"comparison\": differences\n",
        "        }\n",
        "\n",
        "    def benchmark_suite(self, functions: List[Tuple[str, Callable[..., Any]]]) -> Dict[str, Any]:\n",
        "            \"\"\"\n",
        "            Run benchmark suite, calibrate reference values, and then recalculate scores.\n",
        "\n",
        "            Args:\n",
        "                functions: List of (name, function) tuples to benchmark\n",
        "\n",
        "            Returns:\n",
        "                Dictionary with benchmark results and statistics based on calibrated values.\n",
        "            \"\"\"\n",
        "            # --- Step 1: Collect RAW metrics first, without calculating composite scores ---\n",
        "            raw_results = {}\n",
        "            for name, func in functions:\n",
        "                # We call analyze_function with include_composite=False to get only raw CU, EU, etc.\n",
        "                raw_result = self.analyze_function(func, include_composite=False)\n",
        "                raw_results[name] = raw_result\n",
        "\n",
        "            # Extract raw metrics for calibration\n",
        "            raw_metrics_list = list(raw_results.values())\n",
        "\n",
        "            # --- Step 2: Calibrate the reference values based on the collected raw data ---\n",
        "            self.composite_calculator.update_reference_values(raw_metrics_list)\n",
        "            self.benchmark_history.extend(raw_metrics_list)\n",
        "\n",
        "            # --- Step 3: Now, recalculate scores for each function using the NEW calibrated references ---\n",
        "            final_results = {}\n",
        "            for name, raw_result in raw_results.items():\n",
        "                # Now we use the calculator to add composite scores to the existing raw results\n",
        "                final_results[name] = self.composite_calculator.calculate_composite_score(raw_result)\n",
        "\n",
        "            # --- Step 4: Calculate final statistics based on correctly scored results ---\n",
        "            stats = self._calculate_benchmark_stats(final_results)\n",
        "\n",
        "            return {\n",
        "                \"results\": final_results, # Return the correctly calculated results\n",
        "                \"statistics\": stats,\n",
        "                \"updated_references\": self.composite_calculator.reference_values\n",
        "            }\n",
        "\n",
        "    def _calculate_benchmark_stats(self, results: Dict[str, Dict[str, float]]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate statistical summary of benchmark results.\"\"\"\n",
        "        composite_scores = [result[\"COMPOSITE_SCORE\"] for result in results.values()]\n",
        "\n",
        "        return {\n",
        "            \"best_algorithm\": max(results.keys(), key=lambda k: results[k][\"COMPOSITE_SCORE\"]),\n",
        "            \"worst_algorithm\": min(results.keys(), key=lambda k: results[k][\"COMPOSITE_SCORE\"]),\n",
        "            \"average_composite_score\": statistics.mean(composite_scores),\n",
        "            \"median_composite_score\": statistics.median(composite_scores),\n",
        "            \"composite_score_std\": statistics.stdev(composite_scores) if len(composite_scores) > 1 else 0,\n",
        "            \"score_range\": max(composite_scores) - min(composite_scores)\n",
        "        }\n",
        "\n",
        "    def analyze_py_file(self, file_path: str, verbose: bool = True) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Dynamically imports a Python file and analyzes all top-level functions AND methods\n",
        "        within top-level classes.\n",
        "\n",
        "        WARNING: This method executes code from the given file path, which can be a\n",
        "        security risk if the file is not trusted.\n",
        "\n",
        "        Args:\n",
        "            file_path: The full path to the Python (.py) file.\n",
        "            verbose: If True, prints progress and error messages.\n",
        "\n",
        "        Returns:\n",
        "            A list of result dictionaries, one for each function or method found.\n",
        "        \"\"\"\n",
        "        all_executable_results = []\n",
        "\n",
        "        try:\n",
        "            module_name = f\"dynamic_module_{os.path.basename(file_path).replace('.py', '')}\"\n",
        "            spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
        "            if spec is None or spec.loader is None:\n",
        "                if verbose:\n",
        "                    print(f\"Warning: Could not create module spec for {file_path}\")\n",
        "                return []\n",
        "\n",
        "            module = importlib.util.module_from_spec(spec)\n",
        "            spec.loader.exec_module(module)\n",
        "\n",
        "            functions_and_methods_to_analyze = []\n",
        "\n",
        "            for func_name, func_obj in inspect.getmembers(module, inspect.isfunction):\n",
        "                if func_obj.__module__ == module_name:\n",
        "                    functions_and_methods_to_analyze.append((func_name, func_obj))\n",
        "\n",
        "            for class_name, class_obj in inspect.getmembers(module, inspect.isclass):\n",
        "                if class_obj.__module__ == module_name:\n",
        "                    for method_name, method_obj in inspect.getmembers(class_obj, inspect.isfunction):\n",
        "                        descriptive_name = f\"{class_name}.{method_name}\"\n",
        "                        functions_and_methods_to_analyze.append((descriptive_name, method_obj))\n",
        "\n",
        "            if not functions_and_methods_to_analyze:\n",
        "                return [{\n",
        "                    'Source File': os.path.basename(file_path),\n",
        "                    'Function Name': '[No functions or methods found]',\n",
        "                    'COMPOSITE_SCORE': 0, 'SCORE_GRADE': 'N/A'\n",
        "                }]\n",
        "\n",
        "            for name, executable_obj in functions_and_methods_to_analyze:\n",
        "                if verbose:\n",
        "                    print(f\"    > Found '{name}' in {os.path.basename(file_path)}, analyzing...\")\n",
        "                result = self.analyze_function(executable_obj)\n",
        "                result['Source File'] = os.path.basename(file_path)\n",
        "                result['Function Name'] = name\n",
        "                all_executable_results.append(result)\n",
        "\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"Error analyzing Python file {file_path}: {e}\")\n",
        "            return [{\n",
        "                'Source File': os.path.basename(file_path),\n",
        "                'Function Name': f'[Error: {e}]',\n",
        "                'COMPOSITE_SCORE': 0, 'SCORE_GRADE': 'Error'\n",
        "            }]\n",
        "\n",
        "        return all_executable_results\n",
        "\n",
        "\n",
        "def save_enhanced_csv(data: Dict[str, Any], filename: str, report_dir: str) -> None:\n",
        "    \"\"\"\n",
        "    Save enhanced cost data to CSV file with composite scores.\n",
        "\n",
        "    Args:\n",
        "        data: Dictionary with cost metrics and composite scores\n",
        "        filename: Output filename\n",
        "        report_dir: Directory to save reports\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(report_dir, filename)\n",
        "    with open(filepath, mode=\"w\", newline=\"\", encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Metric\", \"Value\", \"Description\"])\n",
        "\n",
        "        # Basic metrics\n",
        "        basic_metrics = [\"CU\", \"EU\", \"CO2\", \"$\"]\n",
        "        for key in basic_metrics:\n",
        "            if key in data:\n",
        "                writer.writerow([key, data[key], f\"Raw {key} value\"])\n",
        "\n",
        "        # Normalized scores\n",
        "        for key in basic_metrics:\n",
        "            normalized_key = f\"{key}_normalized\"\n",
        "            if normalized_key in data:\n",
        "                writer.writerow([normalized_key, data[normalized_key], f\"Normalized {key} score (0-100)\"])\n",
        "\n",
        "        # Composite metrics\n",
        "        if \"COMPOSITE_SCORE\" in data:\n",
        "            writer.writerow([\"COMPOSITE_SCORE\", data[\"COMPOSITE_SCORE\"], \"Unified composite score (0-100)\"])\n",
        "        if \"SCORE_GRADE\" in data:\n",
        "            writer.writerow([\"SCORE_GRADE\", data[\"SCORE_GRADE\"], \"Letter grade rating\"])\n",
        "        if \"EFFICIENCY_RATING\" in data:\n",
        "            writer.writerow([\"EFFICIENCY_RATING\", data[\"EFFICIENCY_RATING\"], \"Efficiency rating\"])\n",
        "\n",
        "\n",
        "def create_enhanced_comparison_chart(\n",
        "    result1: Dict[str, float],\n",
        "    result2: Dict[str, float],\n",
        "    output_filepath: str,  # CHANGED: from report_dir to the full output path\n",
        "    names: Tuple[str, str] = (\"Algorithm v1\", \"Algorithm v2\")\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Create enhanced comparison chart for two algorithms.\n",
        "\n",
        "    Args:\n",
        "        result1: Cost metrics for the first algorithm (e.g., the baseline).\n",
        "        result2: Cost metrics for the second algorithm (e.g., the one to compare).\n",
        "        output_filepath: The full path where the PNG file will be saved.\n",
        "        names: Names for the two algorithms for chart legends.\n",
        "    \"\"\"\n",
        "    # Create subplot layout\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(f'Comparison: \"{names[1]}\" vs. \"{names[0]}\"', fontsize=16) # Add a main title\n",
        "\n",
        "    # --- Raw metrics comparison ---\n",
        "    raw_metrics = [\"CU\", \"EU\", \"CO2\", \"$\"]\n",
        "    values1_raw = [result1.get(m, 0) for m in raw_metrics]\n",
        "    values2_raw = [result2.get(m, 0) for m in raw_metrics]\n",
        "\n",
        "    x = np.arange(len(raw_metrics)) # Use numpy for easier calculations\n",
        "    width = 0.35\n",
        "\n",
        "    ax1.bar(x - width/2, values1_raw, width, label=names[0], color='skyblue', alpha=0.8)\n",
        "    ax1.bar(x + width/2, values2_raw, width, label=names[1], color='lightcoral', alpha=0.8)\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(raw_metrics)\n",
        "    ax1.set_ylabel(\"Raw Values (Log Scale)\")\n",
        "    ax1.set_title(\"Raw Metrics Comparison\")\n",
        "    ax1.legend()\n",
        "    ax1.set_yscale('log')\n",
        "\n",
        "    # --- Normalized scores comparison ---\n",
        "    normalized_metrics = [f\"{m}_normalized\" for m in raw_metrics]\n",
        "    values1_norm = [result1.get(m, 50) for m in normalized_metrics]\n",
        "    values2_norm = [result2.get(m, 50) for m in normalized_metrics]\n",
        "\n",
        "    ax2.bar(x - width/2, values1_norm, width, label=names[0], color='skyblue', alpha=0.8)\n",
        "    ax2.bar(x + width/2, values2_norm, width, label=names[1], color='lightcoral', alpha=0.8)\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels([m.replace('_normalized', '') for m in normalized_metrics])\n",
        "    ax2.set_ylabel(\"Normalized Scores (0-100)\")\n",
        "    ax2.set_title(\"Normalized Scores Comparison\")\n",
        "    ax2.legend()\n",
        "    ax2.set_ylim(0, 105) # Increased ylim for text\n",
        "\n",
        "    # --- Composite score comparison ---\n",
        "    composite1 = result1.get(\"COMPOSITE_SCORE\", 50)\n",
        "    composite2 = result2.get(\"COMPOSITE_SCORE\", 50)\n",
        "\n",
        "    ax3.bar([names[0], names[1]], [composite1, composite2],\n",
        "            color=['skyblue', 'lightcoral'], alpha=0.8)\n",
        "    ax3.set_ylabel(\"Composite Score (0-100)\")\n",
        "    ax3.set_title(\"Composite Score Comparison\")\n",
        "    ax3.set_ylim(0, 105) # Increased ylim for text\n",
        "\n",
        "    # Add score values on bars\n",
        "    for i, (name, score) in enumerate(zip([names[0], names[1]], [composite1, composite2])):\n",
        "        ax3.text(i, score, f\"{score:.1f}\", ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "    # --- Radar chart for multi-dimensional comparison ---\n",
        "    labels = np.array(raw_metrics)\n",
        "    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    ax4 = plt.subplot(2, 2, 4, polar=True) # Recreate axis as polar\n",
        "\n",
        "    values1_radar = values1_norm + [values1_norm[0]]\n",
        "    values2_radar = values2_norm + [values2_norm[0]]\n",
        "\n",
        "    ax4.plot(angles, values1_radar, 'o-', linewidth=2, label=names[0], color='skyblue')\n",
        "    ax4.fill(angles, values1_radar, 'skyblue', alpha=0.25)\n",
        "    ax4.plot(angles, values2_radar, 'o-', linewidth=2, label=names[1], color='lightcoral')\n",
        "    ax4.fill(angles, values2_radar, 'lightcoral', alpha=0.25)\n",
        "\n",
        "    ax4.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
        "    ax4.set_ylim(0, 100)\n",
        "    ax4.set_title(\"Multi-dimensional Performance Radar\", y=1.1)\n",
        "    ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
        "\n",
        "    # --- Save the chart ---\n",
        "    # The calling code is now responsible for creating the directory.\n",
        "    # The function no longer creates directories, it just saves the file.\n",
        "    os.makedirs(output_filepath, exist_ok=True)\n",
        "    plt.savefig(output_filepath, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def create_enhanced_comparison_chart(\n",
        "    result1: Dict[str, float],\n",
        "    result2: Dict[str, float],\n",
        "    output_filepath: str,  # Takes the full path to the output file\n",
        "    names: Tuple[str, str] = (\"Algorithm v1\", \"Algorithm v2\")\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Creates an enhanced comparison chart and saves it to a specified file path.\n",
        "\n",
        "    Args:\n",
        "        result1: Cost metrics for the baseline algorithm.\n",
        "        result2: Cost metrics for the algorithm to compare.\n",
        "        output_filepath: The full path where the PNG file will be saved.\n",
        "        names: Names for the two algorithms for chart legends.\n",
        "    \"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(f'Comparison: \"{names[1]}\" vs. \"{names[0]}\"', fontsize=16)\n",
        "\n",
        "    # Raw metrics comparison\n",
        "    raw_metrics = [\"CU\", \"EU\", \"CO2\", \"$\"]\n",
        "    values1_raw = [result1.get(m, 0) for m in raw_metrics]\n",
        "    values2_raw = [result2.get(m, 0) for m in raw_metrics]\n",
        "    x = np.arange(len(raw_metrics))\n",
        "    width = 0.35\n",
        "    ax1.bar(x - width/2, values1_raw, width, label=names[0], color='skyblue', alpha=0.8)\n",
        "    ax1.bar(x + width/2, values2_raw, width, label=names[1], color='lightcoral', alpha=0.8)\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(raw_metrics)\n",
        "    ax1.set_ylabel(\"Raw Values (Log Scale)\")\n",
        "    ax1.set_title(\"Raw Metrics Comparison\")\n",
        "    ax1.legend()\n",
        "    ax1.set_yscale('log')\n",
        "\n",
        "    # Normalized scores comparison\n",
        "    normalized_metrics = [f\"{m}_normalized\" for m in raw_metrics]\n",
        "    values1_norm = [result1.get(m, 50) for m in normalized_metrics]\n",
        "    values2_norm = [result2.get(m, 50) for m in normalized_metrics]\n",
        "    ax2.bar(x - width/2, values1_norm, width, label=names[0], color='skyblue', alpha=0.8)\n",
        "    ax2.bar(x + width/2, values2_norm, width, label=names[1], color='lightcoral', alpha=0.8)\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels([m.replace('_normalized', '') for m in normalized_metrics])\n",
        "    ax2.set_ylabel(\"Normalized Scores (0-100)\")\n",
        "    ax2.set_title(\"Normalized Scores Comparison\")\n",
        "    ax2.legend()\n",
        "    ax2.set_ylim(0, 105)\n",
        "\n",
        "    # Composite score comparison\n",
        "    composite1 = result1.get(\"COMPOSITE_SCORE\", 50)\n",
        "    composite2 = result2.get(\"COMPOSITE_SCORE\", 50)\n",
        "    ax3.bar([names[0], names[1]], [composite1, composite2], color=['skyblue', 'lightcoral'], alpha=0.8)\n",
        "    ax3.set_ylabel(\"Composite Score (0-100)\")\n",
        "    ax3.set_title(\"Composite Score Comparison\")\n",
        "    ax3.set_ylim(0, 105)\n",
        "    for i, score in enumerate([composite1, composite2]):\n",
        "        ax3.text(i, score, f\"{score:.1f}\", ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "    # Radar chart\n",
        "    labels = np.array(raw_metrics)\n",
        "    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "    ax4 = plt.subplot(2, 2, 4, polar=True)\n",
        "    values1_radar = values1_norm + [values1_norm[0]]\n",
        "    values2_radar = values2_norm + [values2_norm[0]]\n",
        "    ax4.plot(angles, values1_radar, 'o-', linewidth=2, label=names[0], color='skyblue')\n",
        "    ax4.fill(angles, values1_radar, 'skyblue', alpha=0.25)\n",
        "    ax4.plot(angles, values2_radar, 'o-', linewidth=2, label=names[1], color='lightcoral')\n",
        "    ax4.fill(angles, values2_radar, 'lightcoral', alpha=0.25)\n",
        "    ax4.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
        "    ax4.set_ylim(0, 100)\n",
        "    ax4.set_title(\"Multi-dimensional Performance Radar\", y=1.1)\n",
        "    ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "\n",
        "    # The function ONLY saves the file. It does not create directories.\n",
        "    plt.savefig(output_filepath, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"Enhanced main execution function with composite scoring examples.\"\"\"\n",
        "    # Architecture detection and analyzer initialization\n",
        "    detected_arch = platform.machine().lower()\n",
        "    print(f\"[Init] Detected architecture: {detected_arch}\")\n",
        "\n",
        "    # Initialize enhanced analyzer with profile-based weights\n",
        "    print(f\"[Config] Available profiles: {list(PROFILE_WEIGHTS.keys())}\")\n",
        "\n",
        "    # Example: Use RESEARCH profile for academic/research scenarios\n",
        "    analyzer = EnhancedCostAnalyzer(arch=detected_arch, profile=\"RESEARCH\")\n",
        "\n",
        "    # Print current profile info\n",
        "    profile_info = analyzer.composite_calculator.get_profile_info()\n",
        "    print(f\"[Config] Using profile: {profile_info['profile']}\")\n",
        "    print(f\"[Config] Profile description: {profile_info['description']}\")\n",
        "    print(f\"[Config] Weights: {profile_info['weights']}\")\n",
        "\n",
        "    # Single function analysis with composite scoring\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENHANCED ALGORITHM ANALYSIS WITH COMPOSITE SCORING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    result_linear = analyzer.analyze_function(algorithm_linear)\n",
        "    result_constant = analyzer.analyze_function(algorithm_constant)\n",
        "\n",
        "    print(f\"\\n[Analysis] Linear Algorithm Assessment:\")\n",
        "    for key, value in result_linear.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            print(f\"  {key}: {value:.6f}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(f\"\\n[Analysis] Constant Algorithm Assessment:\")\n",
        "    for key, value in result_constant.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            print(f\"  {key}: {value:.6f}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "    # Detailed function comparison\n",
        "    print(f\"\\n[Comparison] Detailed Algorithm Comparison:\")\n",
        "    comparison = analyzer.compare_functions(algorithm_linear, algorithm_constant)\n",
        "\n",
        "    print(f\"  Original Algorithm:\")\n",
        "    print(f\"    Composite Score: {comparison['old_metrics']['COMPOSITE_SCORE']:.2f} ({comparison['old_metrics']['SCORE_GRADE']})\")\n",
        "    print(f\"    Efficiency Rating: {comparison['old_metrics']['EFFICIENCY_RATING']}\")\n",
        "\n",
        "    print(f\"  Optimized Algorithm:\")\n",
        "    print(f\"    Composite Score: {comparison['new_metrics']['COMPOSITE_SCORE']:.2f} ({comparison['new_metrics']['SCORE_GRADE']})\")\n",
        "    print(f\"    Efficiency Rating: {comparison['new_metrics']['EFFICIENCY_RATING']}\")\n",
        "\n",
        "    print(f\"  Improvement Analysis:\")\n",
        "    print(f\"    Score Improvement: {comparison['comparison']['COMPOSITE_SCORE_diff']:.2f} points\")\n",
        "    print(f\"    Better Algorithm: {'Yes' if comparison['comparison']['improvement'] else 'No'}\")\n",
        "\n",
        "    for metric in [\"CU\", \"EU\", \"CO2\", \"$\"]:\n",
        "        change = comparison['comparison'][f'{metric}_percent_change']\n",
        "        print(f\"    {metric} Change: {change:.1f}%\")\n",
        "\n",
        "    # Benchmark suite analysis\n",
        "    print(f\"\\n[Benchmark] Running Algorithm Suite Analysis:\")\n",
        "\n",
        "    algorithms_suite = [\n",
        "        (\"Linear_O(n)\", algorithm_linear),\n",
        "        (\"Constant_O(1)\", algorithm_constant),\n",
        "        (\"Quadratic_O(n)\", algorithm_quadratic),\n",
        "        (\"Recursive_Fib\", algorithm_recursive)\n",
        "    ]\n",
        "\n",
        "    benchmark_results = analyzer.benchmark_suite(algorithms_suite)\n",
        "\n",
        "    print(f\"  Best Algorithm: {benchmark_results['statistics']['best_algorithm']}\")\n",
        "    print(f\"  Worst Algorithm: {benchmark_results['statistics']['worst_algorithm']}\")\n",
        "    print(f\"  Average Composite Score: {benchmark_results['statistics']['average_composite_score']:.2f}\")\n",
        "    print(f\"  Score Standard Deviation: {benchmark_results['statistics']['composite_score_std']:.2f}\")\n",
        "    print(f\"  Performance Range: {benchmark_results['statistics']['score_range']:.2f} points\")\n",
        "\n",
        "    # Updated reference values after benchmarking\n",
        "    print(f\"\\n[Calibration] Updated Reference Values:\")\n",
        "    for metric, refs in benchmark_results['updated_references'].items():\n",
        "        print(f\"  {metric}: min={refs['min']:.6f}, max={refs['max']:.6f}, typical={refs['typical']:.6f}\")\n",
        "\n",
        "    # Profile comparison example\n",
        "    print(f\"\\n[Profile Comparison] Testing different profiles:\")\n",
        "    profiles_to_test = [\"HPC\", \"MOBILE\", \"COMMERCIAL\"]\n",
        "    for test_profile in profiles_to_test:\n",
        "        test_analyzer = EnhancedCostAnalyzer(arch=detected_arch, profile=test_profile)\n",
        "        test_result = test_analyzer.analyze_function(algorithm_constant)\n",
        "        print(f\"  {test_profile}: Composite Score = {test_result['COMPOSITE_SCORE']:.2f} ({test_result['SCORE_GRADE']})\")\n",
        "\n",
        "    # Analyze external files if available\n",
        "    llvm_path = \"examples/sample.ll\"\n",
        "    if os.path.exists(llvm_path):\n",
        "        llvm_result = analyzer.analyze_llvm_ir(llvm_path)\n",
        "        print(f\"\\n[LLVM] Assessment of '{llvm_path}':\")\n",
        "        print(f\"  Composite Score: {llvm_result['COMPOSITE_SCORE']:.2f} ({llvm_result['SCORE_GRADE']})\")\n",
        "\n",
        "    ptx_path = \"examples/sample.ptx\"\n",
        "    if os.path.exists(ptx_path):\n",
        "        ptx_result = analyzer.analyze_ptx(ptx_path)\n",
        "        print(f\"\\n[PTX] Assessment of '{ptx_path}':\")\n",
        "        print(f\"  Composite Score: {ptx_result['COMPOSITE_SCORE']:.2f} ({ptx_result['SCORE_GRADE']})\")\n",
        "\n",
        "    # Environmental impact analysis\n",
        "    carbon_intensity = analyzer.fetch_carbon_intensity()\n",
        "    print(f\"\\n[Environment] Current carbon intensity: {carbon_intensity:.6f} kgCO2/kWh\")\n",
        "\n",
        "    # Save enhanced reports\n",
        "    report_dir = \"enhanced_reports\"\n",
        "    os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "    # Save individual results\n",
        "    save_enhanced_csv(result_linear, \"linear_algorithm_enhanced.csv\", report_dir)\n",
        "    save_enhanced_csv(result_constant, \"constant_algorithm_enhanced.csv\", report_dir)\n",
        "\n",
        "    # Save comparison results\n",
        "    with open(os.path.join(report_dir, \"detailed_comparison.json\"), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(comparison, f, indent=4)\n",
        "\n",
        "    # Save benchmark results\n",
        "    with open(os.path.join(report_dir, \"benchmark_suite_results.json\"), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(benchmark_results, f, indent=4)\n",
        "\n",
        "    # Create enhanced visualizations\n",
        "    create_enhanced_comparison_chart(\n",
        "        result_linear, result_constant, report_dir,\n",
        "        names=(\"Linear O(n)\", \"Constant O(1)\")\n",
        "    )\n",
        "\n",
        "    create_benchmark_summary_chart(benchmark_results, report_dir)\n",
        "\n",
        "    # Generate comprehensive summary report\n",
        "    summary_report = {\n",
        "        \"analysis_timestamp\": platform.platform(),\n",
        "        \"architecture\": detected_arch,\n",
        "        \"composite_weights\": profile_info['weights'],\n",
        "        \"best_single_algorithm\": {\n",
        "            \"name\": \"Constant O(1)\",\n",
        "            \"composite_score\": result_constant[\"COMPOSITE_SCORE\"],\n",
        "            \"grade\": result_constant[\"SCORE_GRADE\"]\n",
        "        },\n",
        "        \"benchmark_summary\": benchmark_results[\"statistics\"],\n",
        "        \"recommendations\": generate_recommendations(benchmark_results, profile_info)\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(report_dir, \"comprehensive_summary.json\"), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(summary_report, f, indent=4)\n",
        "\n",
        "    print(f\"\\n[Complete] Enhanced reports saved to '{report_dir}' directory\")\n",
        "    print(f\"[Complete] Generated files:\")\n",
        "    print(f\"  - Individual algorithm assessments (CSV)\")\n",
        "    print(f\"  - Detailed comparison analysis (JSON)\")\n",
        "    print(f\"  - Benchmark suite results (JSON)\")\n",
        "    print(f\"  - Enhanced comparison charts (PNG)\")\n",
        "    print(f\"  - Benchmark summary visualization (PNG)\")\n",
        "    print(f\"  - Comprehensive summary report (JSON)\")\n",
        "\n",
        "\n",
        "def generate_recommendations(\n",
        "    benchmark_results: Dict[str, Any],\n",
        "    profile_info: Optional[Dict[str, Any]] = None\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate algorithm optimization recommendations based on benchmark results.\n",
        "\n",
        "    Args:\n",
        "        benchmark_results: Results from benchmark suite\n",
        "\n",
        "    Returns:\n",
        "        List of recommendation strings\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "    stats = benchmark_results[\"statistics\"]\n",
        "    results = benchmark_results[\"results\"]\n",
        "\n",
        "    # Add profile-specific recommendations\n",
        "    if profile_info:\n",
        "        recommendations.append(\n",
        "            f\"Analysis performed using '{profile_info['profile']}' profile: \"\n",
        "            f\"{profile_info['description']}\"\n",
        "        )\n",
        "\n",
        "    best_alg = stats[\"best_algorithm\"]\n",
        "    worst_alg = stats[\"worst_algorithm\"]\n",
        "\n",
        "    recommendations.append(\n",
        "        f\"Use '{best_alg}' for optimal performance with composite score of \"\n",
        "        f\"{results[best_alg]['COMPOSITE_SCORE']:.1f}\"\n",
        "    )\n",
        "\n",
        "    recommendations.append(\n",
        "        f\"Avoid '{worst_alg}' due to poor performance with composite score of \"\n",
        "        f\"{results[worst_alg]['COMPOSITE_SCORE']:.1f}\"\n",
        "    )\n",
        "\n",
        "    # Find algorithms with good energy efficiency\n",
        "    energy_efficient = min(results.keys(),\n",
        "                          key=lambda k: results[k].get('EU_normalized', 50))\n",
        "    recommendations.append(\n",
        "        f\"For energy-critical applications, consider '{energy_efficient}' \"\n",
        "        f\"with highest energy efficiency score\"\n",
        "    )\n",
        "\n",
        "    # Find algorithms with low environmental impact\n",
        "    eco_friendly = min(results.keys(),\n",
        "                      key=lambda k: results[k].get('CO2_normalized', 50))\n",
        "    recommendations.append(\n",
        "        f\"For environmentally conscious deployment, '{eco_friendly}' \"\n",
        "        f\"has the lowest carbon footprint\"\n",
        "    )\n",
        "\n",
        "    if stats[\"score_range\"] > 20:\n",
        "        recommendations.append(\n",
        "            \"Large performance variation detected - consider algorithm selection \"\n",
        "            \"based on specific use case requirements\"\n",
        "        )\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "def make_safe_filename(name: str) -> str:\n",
        "    \"\"\"Converts a string into a safe filename by removing special characters.\"\"\"\n",
        "    name = name.replace(' ', '_').replace('^', '').replace('(', '').replace(')', '')\n",
        "    safe_name = re.sub(r'(?u)[^-\\w.]', '', name)\n",
        "    return safe_name\n",
        "\n",
        "\n",
        "def create_file_performance_scatterplot(\n",
        "    data: pd.DataFrame,\n",
        "    output_filepath: str,\n",
        "    y_axis_metric: str = 'CU'\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Creates a custom 2D scatter plot for file performance analysis, limited to the top 20 files.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The DataFrame with analysis results.\n",
        "        output_filepath (str): The full path where the PNG file will be saved.\n",
        "        y_axis_metric (str): The metric to use for the Y-axis.\n",
        "    \"\"\"\n",
        "    if data.empty:\n",
        "        print(\"[Chart Info] Cannot generate scatter plot: The input DataFrame is empty.\")\n",
        "        return\n",
        "\n",
        "    required_cols = ['COMPOSITE_SCORE', 'SCORE_GRADE', 'File Type', y_axis_metric]\n",
        "    if not all(col in data.columns for col in required_cols):\n",
        "        print(f\"[Chart Error] Input data is missing one of the required columns: {required_cols}\")\n",
        "        return\n",
        "\n",
        "    plot_df = data.nlargest(20, 'COMPOSITE_SCORE').copy()\n",
        "    print(f\"[Chart Info] Displaying top {len(plot_df)} files sorted by COMPOSITE_SCORE.\")\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Define lists of distinct markers and colors to cycle through\n",
        "    markers = ['o', 's', '^', 'P', '*', 'X', 'D', 'v', '<', '>', 'p', 'h', '+', 'd', 'H']\n",
        "    # Use a colormap to get a variety of distinct colors\n",
        "    cmap = plt.get_cmap('tab20')\n",
        "\n",
        "    legend_handles = []\n",
        "\n",
        "    for i, (index, row) in enumerate(plot_df.iterrows()):\n",
        "        marker = markers[i % len(markers)]\n",
        "        color = cmap(i / len(plot_df))\n",
        "        x_val = row['COMPOSITE_SCORE']\n",
        "        y_val = row[y_axis_metric]\n",
        "\n",
        "        plt.scatter(x_val, y_val, marker=marker, s=120, label=index, color=color) # CHANGED: Apply color\n",
        "\n",
        "        legend_label = f\"{index} ({row['File Type']})\"\n",
        "        legend_handles.append(\n",
        "            mlines.Line2D([], [], color=color, marker=marker, linestyle='None', # CHANGED: Use point's color\n",
        "                          markersize=10, label=legend_label)\n",
        "        )\n",
        "\n",
        "        plt.text(x_val, y_val, f\" {row['SCORE_GRADE']}\",\n",
        "                 verticalalignment='bottom', ha='left', fontsize=9, color='darkred',\n",
        "                 bbox=dict(facecolor='white', alpha=0.5, edgecolor='none', boxstyle='round,pad=0.1')) # Added background to text\n",
        "\n",
        "    # --- Final Touches ---\n",
        "    plt.title(f'File Performance Analysis: Score vs. {y_axis_metric} Cost', fontsize=16)\n",
        "    plt.xlabel('Composite Score (Higher is Better)', fontsize=12)\n",
        "    plt.ylabel(f'{y_axis_metric} Cost (Lower is Better)', fontsize=12)\n",
        "    plt.grid(True, which='major', linestyle='--', linewidth=0.5)\n",
        "\n",
        "    # CHANGED: Place the legend inside the plot. 'best' tries to find the least obstructive location.\n",
        "    plt.legend(handles=legend_handles, title='Files', loc='best', fontsize='small')\n",
        "\n",
        "    # Use the standard tight_layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    output_dir = os.path.dirname(output_filepath)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    plt.savefig(output_filepath, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def analyze_repository(\n",
        "    repo_path: str,\n",
        "    detected_arch: str,\n",
        "    verbose: bool = True\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Performs a self-contained, comprehensive analysis of a code repository.\n",
        "    This version correctly calculates the TOTAL row based on the average of profile scores.\n",
        "\n",
        "    Args:\n",
        "        repo_path (str): The path to the repository directory to analyze.\n",
        "        detected_arch (str): The architecture string for the cost model.\n",
        "        verbose (bool): If True, prints progress messages.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A summary DataFrame showing aggregated costs under different profiles.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(repo_path):\n",
        "        if verbose:\n",
        "            print(f\"[Error] Repository path not found: {repo_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    file_types_to_analyze = {\n",
        "        'Python': {'extension': 'py', 'analysis_key': 'analyze_py_file'},\n",
        "        'LLVM IR': {'extension': 'll', 'analysis_key': 'analyze_llvm_ir'},\n",
        "        'PTX GPU': {'extension': 'ptx', 'analysis_key': 'analyze_ptx'}\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n--- Step 1 of 2: Collecting and aggregating raw performance data... ---\")\n",
        "    raw_analyzer = EnhancedCostAnalyzer(arch=detected_arch)\n",
        "    aggregated_raw_metrics = {}\n",
        "\n",
        "    for file_type_name, config in file_types_to_analyze.items():\n",
        "        search_pattern = os.path.join(repo_path, f\"**/*.{config['extension']}\")\n",
        "        found_files = glob.glob(search_pattern, recursive=True)\n",
        "        if not found_files: continue\n",
        "\n",
        "        type_aggregator = {'CU': 0, 'EU': 0, 'CO2': 0, '$': 0, 'function_count': 0, 'file_count': len(found_files)}\n",
        "        analysis_func = getattr(raw_analyzer, config['analysis_key'])\n",
        "\n",
        "        for file_path in found_files:\n",
        "            #        \n",
        "            if config['analysis_key'] == 'analyze_py_file':\n",
        "                # analyze_py_file   verbose   \n",
        "                file_results = analysis_func(file_path, verbose=verbose)\n",
        "            else:\n",
        "                #     ,     \n",
        "                file_results = [analysis_func(file_path)]\n",
        "\n",
        "            for result in file_results:\n",
        "                if not result: continue\n",
        "                for metric in ['CU', 'EU', 'CO2', '$']:\n",
        "                    type_aggregator[metric] += result.get(metric, 0)\n",
        "                func_name = result.get(\"Function Name\", \"\")\n",
        "                if func_name and not func_name.startswith('['):\n",
        "                    type_aggregator['function_count'] += 1\n",
        "\n",
        "        if type_aggregator['CU'] > 0:\n",
        "            aggregated_raw_metrics[file_type_name] = type_aggregator\n",
        "\n",
        "    if not aggregated_raw_metrics:\n",
        "        if verbose:\n",
        "            print(\"No analyzable content with non-zero cost found in the repository.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n--- Step 2 of 2: Applying each profile to the aggregated data... ---\")\n",
        "    final_results_list = []\n",
        "\n",
        "    for profile_name in PROFILE_WEIGHTS.keys():\n",
        "        if verbose:\n",
        "            print(f\"  > Scoring with profile: [{profile_name}]\")\n",
        "        profile_analyzer = EnhancedCostAnalyzer(arch=detected_arch, profile=profile_name)\n",
        "\n",
        "        for file_type_name, raw_data in aggregated_raw_metrics.items():\n",
        "            scored_row = profile_analyzer.composite_calculator.calculate_composite_score(raw_data)\n",
        "            scored_row['PROFILE NAME'] = profile_name\n",
        "            scored_row['File Type'] = f\"{file_type_name} ({raw_data.get('file_count', 0)})\"\n",
        "            scored_row['Function Name'] = raw_data.get('function_count', 0)\n",
        "            final_results_list.append(scored_row)\n",
        "\n",
        "    repo_df = pd.DataFrame(final_results_list)\n",
        "\n",
        "    if not repo_df.empty:\n",
        "        average_composite_score = repo_df['COMPOSITE_SCORE'].mean()\n",
        "        total_metrics = repo_df.loc[repo_df['PROFILE NAME'] == 'DEFAULT', ['CU', 'EU', 'CO2', '$']].sum().to_dict()\n",
        "        temp_calculator = CompositeScoreCalculator()\n",
        "        average_grade = temp_calculator._get_score_grade(average_composite_score)\n",
        "        total_file_count = sum(d.get('file_count', 0) for d in aggregated_raw_metrics.values())\n",
        "        total_func_count = sum(d.get('function_count', 0) for d in aggregated_raw_metrics.values())\n",
        "\n",
        "        total_row = {\n",
        "            'PROFILE NAME': 'TOTAL',\n",
        "            'File Type': f\"All Files ({total_file_count})\",\n",
        "            'Function Name': total_func_count,\n",
        "            'COMPOSITE_SCORE': average_composite_score,\n",
        "            'SCORE_GRADE': average_grade,\n",
        "            'CU': total_metrics.get('CU', 0),\n",
        "            'EU': total_metrics.get('EU', 0),\n",
        "            'CO2': total_metrics.get('CO2', 0),\n",
        "            '$': total_metrics.get('$', 0)\n",
        "        }\n",
        "\n",
        "        final_df = pd.concat([repo_df, pd.DataFrame([total_row])], ignore_index=True)\n",
        "    else:\n",
        "        final_df = repo_df\n",
        "\n",
        "    final_columns = ['PROFILE NAME', 'File Type', 'Function Name', 'COMPOSITE_SCORE', 'SCORE_GRADE', 'CU', 'EU', 'CO2', '$']\n",
        "    final_df = final_df.reindex(columns=final_columns)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "\n",
        "def create_repository_comparison_chart(\n",
        "    repo_data: Dict[str, pd.DataFrame],\n",
        "    output_filepath: str,\n",
        "    profile_to_plot: str = \"TOTAL\"\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Creates a comparison chart for multiple repositories based on a specific profile row.\n",
        "\n",
        "    Args:\n",
        "        repo_data (Dict[str, pd.DataFrame]): A dictionary mapping repository names to their analysis DataFrames.\n",
        "        output_filepath (str): The full path where the PNG file will be saved.\n",
        "        profile_to_plot (str): The name of the profile row (e.g., 'TOTAL', 'RESEARCH') to use for plotting.\n",
        "    \"\"\"\n",
        "    repo_names = []\n",
        "    composite_scores = []\n",
        "    raw_metrics_data = {'CU': [], 'EU': [], 'CO2': [], '$': []}\n",
        "    metrics_to_plot = list(raw_metrics_data.keys())\n",
        "\n",
        "    for name, df in repo_data.items():\n",
        "        if profile_to_plot in df.index:\n",
        "            repo_names.append(name)\n",
        "            row = df.loc[profile_to_plot]\n",
        "            composite_scores.append(row['COMPOSITE_SCORE'])\n",
        "            for metric in metrics_to_plot:\n",
        "                raw_metrics_data[metric].append(row[metric])\n",
        "\n",
        "    if not repo_names:\n",
        "        print(f\"[Chart Error] No data found for profile '{profile_to_plot}' in any repository.\")\n",
        "        return\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7), gridspec_kw={'width_ratios': [1, 2]})\n",
        "    fig.suptitle(f'Repository Performance Comparison (Profile: {profile_to_plot})', fontsize=16)\n",
        "\n",
        "    # --- Subplot 1: Composite Score (Higher is Better) ---\n",
        "    x_pos_ax1 = np.arange(len(repo_names))\n",
        "    ax1.bar(x_pos_ax1, composite_scores, color='skyblue', alpha=0.8)\n",
        "    ax1.set_title('Composite Score Comparison (Total)')\n",
        "    ax1.set_ylabel('Score (Higher is Better)')\n",
        "    ax1.set_xticks(x_pos_ax1)\n",
        "    ax1.set_xticklabels(repo_names, rotation=45, ha='right')\n",
        "    ax1.grid(True, axis='y', linestyle='--', linewidth=0.5, alpha=0.7) # Added horizontal grid for ax1 too\n",
        "\n",
        "    for i, score in enumerate(composite_scores):\n",
        "        ax1.text(i, score, f'{score:.1f}', ha='center', va='bottom', fontsize=10)\n",
        "    if composite_scores:\n",
        "        ax1.set_ylim(0, max(composite_scores) * 1.15)\n",
        "\n",
        "    # --- Subplot 2: Raw Costs (Lower is Better) - Grouped Bar Chart ---\n",
        "    x_pos_ax2 = np.arange(len(repo_names))\n",
        "    n_metrics = len(metrics_to_plot)\n",
        "    total_bar_width, bar_width = 0.8, 0.8 / n_metrics\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        offset = -total_bar_width / 2 + i * bar_width + bar_width / 2\n",
        "        ax2.bar(x_pos_ax2 + offset, raw_metrics_data[metric], bar_width, label=metric)\n",
        "\n",
        "    ax2.set_title('Aggregated Raw Costs')\n",
        "    ax2.set_ylabel('Cost Values (Log Scale, Lower is Better)')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.set_xticks(x_pos_ax2)\n",
        "    ax2.set_xticklabels(repo_names, rotation=45, ha='right')\n",
        "    ax2.legend(title=\"Metrics\")\n",
        "\n",
        "    # --- Grid and Axis Configuration for ax2 ---\n",
        "    # 1. Add horizontal grid lines\n",
        "    ax2.grid(True, axis='y', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "    # 2. Add vertical grid lines between groups\n",
        "    ax2.set_xticks(x_pos_ax2 + total_bar_width/2 + (bar_width/2 if n_metrics > 1 else 0.1), minor=True) # Position minor ticks between groups\n",
        "    ax2.grid(True, axis='x', which='minor', linestyle='-', linewidth=0.7, color='black', alpha=0.6) # Draw grid for minor ticks\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "\n",
        "    output_dir = os.path.dirname(output_filepath)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    plt.savefig(output_filepath, dpi=300, bbox_inches='tight')\n",
        "    # plt.show() # show() is not needed if we display the image file directly\n",
        "    plt.close(fig) # Close the plot to free up memory\n",
        "\n"
      ],
      "metadata": {
        "id": "MJ0VhxpWN0D3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data generation"
      ],
      "metadata": {
        "id": "r786tZeynnjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def algorithm_constant(n: int) -> int:\n",
        "    \"\"\"Constant time O(1) - Mathematical formula.\"\"\"\n",
        "    # Uses the arithmetic progression sum formula.\n",
        "    return n * (n - 1) // 2\n",
        "\n",
        "def algorithm_log_n_binary_search(n: int) -> int:\n",
        "    \"\"\"Logarithmic time O(log n) - Binary search.\"\"\"\n",
        "    # Create a sorted array for searching.\n",
        "    data = list(range(n))\n",
        "    # Search for an element that is definitely not in the list to ensure worst-case scenario.\n",
        "    target = n + 1\n",
        "    low, high = 0, len(data) - 1\n",
        "    while low <= high:\n",
        "        mid = (low + high) // 2\n",
        "        if data[mid] < target:\n",
        "            low = mid + 1\n",
        "        else:\n",
        "            high = mid - 1\n",
        "    return low\n",
        "\n",
        "def algorithm_sqrt_n_primality_test(n: int) -> bool:\n",
        "    \"\"\"Time complexity O(sqrt(n)) - Simple primality test.\"\"\"\n",
        "    if n <= 1: return False\n",
        "    if n <= 3: return True\n",
        "    if n % 2 == 0 or n % 3 == 0: return False\n",
        "    i = 5\n",
        "    while i * i <= n:\n",
        "        if n % i == 0 or n % (i + 2) == 0:\n",
        "            return False\n",
        "        i += 6\n",
        "    return True\n",
        "\n",
        "def algorithm_linear_sum(n: int) -> int:\n",
        "    \"\"\"Linear time O(n) - Summation. A basic example.\"\"\"\n",
        "    return sum(i for i in range(n))\n",
        "\n",
        "def algorithm_linear_list_append(n: int) -> list:\n",
        "    \"\"\"Linear time O(n) - List creation using append.\"\"\"\n",
        "    result = []\n",
        "    for i in range(n):\n",
        "        result.append(i)\n",
        "    return result\n",
        "\n",
        "def algorithm_linear_string_concat(n: int) -> int:\n",
        "    \"\"\"Linear time O(n), but inefficient due to string immutability - String concatenation.\"\"\"\n",
        "    s = \"\"\n",
        "    for i in range(n):\n",
        "        # Inefficient operation, creates many new string objects.\n",
        "        s += \"*\"\n",
        "    return len(s)\n",
        "\n",
        "def algorithm_linear_dict_creation(n: int) -> dict:\n",
        "    \"\"\"Linear time O(n) - Dictionary creation.\"\"\"\n",
        "    d = {}\n",
        "    for i in range(n):\n",
        "        d[i] = i * i\n",
        "    return d\n",
        "\n",
        "def algorithm_linear_factorial_iter(n: int) -> int:\n",
        "    \"\"\"Linear time O(n) - Iterative factorial (many multiplication operations).\"\"\"\n",
        "    if n < 0: return 0\n",
        "    res = 1\n",
        "    for i in range(1, n + 1):\n",
        "        res *= i\n",
        "    return res\n",
        "\n",
        "def algorithm_linear_recursive_power(n: int) -> int:\n",
        "    \"\"\"Linear time O(n) relative to the exponent - Recursive power calculation.\"\"\"\n",
        "    base = 2\n",
        "    def power(b, p):\n",
        "        if p == 0:\n",
        "            return 1\n",
        "        return b * power(b, p-1)\n",
        "    # Using n as the exponent.\n",
        "    return power(base, n)\n",
        "\n",
        "def algorithm_n_log_n_sort(n: int) -> list:\n",
        "    \"\"\"Log-linear time O(n log n) - Sorting.\"\"\"\n",
        "    # Create a list of random numbers for demonstration.\n",
        "    data = [random.randint(0, n) for _ in range(n)]\n",
        "    return sorted(data)\n",
        "\n",
        "def algorithm_quadratic_loops(n: int) -> int:\n",
        "    \"\"\"Quadratic time O(n^2) - Nested loops.\"\"\"\n",
        "    total = 0\n",
        "    for i in range(n):\n",
        "        for j in range(i):\n",
        "            total += i * j\n",
        "    return total\n",
        "\n",
        "def algorithm_quadratic_list_search(n: int) -> int:\n",
        "    \"\"\"Quadratic time O(n^2) - Searching for common elements in lists.\"\"\"\n",
        "    list1 = list(range(n))\n",
        "    list2 = list(range(n//2, n + n//2))\n",
        "    count = 0\n",
        "    for item1 in list1:\n",
        "        for item2 in list2:\n",
        "            if item1 == item2:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "def algorithm_cubic_loops(n: int) -> int:\n",
        "    \"\"\"Cubic time O(n^3) - Triple nested loops.\n",
        "    WARNING: Use n < 50, as it can be slow.\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            for k in range(n):\n",
        "                total += 1\n",
        "    return total\n",
        "\n",
        "def algorithm_exponential_fib(n: int) -> int:\n",
        "    \"\"\"Exponential time O(2^n) - Naive Fibonacci recursion.\n",
        "    WARNING: Use n < 15, otherwise it will be very slow.\n",
        "    \"\"\"\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return algorithm_exponential_fib(n-1) + algorithm_exponential_fib(n-2)\n",
        "\n",
        "def algorithm_factorial_permutations(n: int) -> int:\n",
        "    \"\"\"Factorial time O(n!) - Permutation generation.\n",
        "    WARNING: Use n < 8, this is very resource-intensive.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    def generate_permutations(arr, l, r):\n",
        "        nonlocal count\n",
        "        if l == r:\n",
        "            count += 1\n",
        "        else:\n",
        "            for i in range(l, r + 1):\n",
        "                arr[l], arr[i] = arr[i], arr[l]\n",
        "                generate_permutations(arr, l + 1, r)\n",
        "                arr[l], arr[i] = arr[i], arr[l] # backtrack\n",
        "\n",
        "    elements = list(range(n))\n",
        "    generate_permutations(elements, 0, len(elements) - 1)\n",
        "    return count\n",
        "\n",
        "# --- Dictionary to store all algorithms ---\n",
        "# Key: human-readable name, Value: function reference\n",
        "algorithms_collection = {\n",
        "    \"Constant_O(1)_Formula\": algorithm_constant,\n",
        "    \"Logarithmic_O(log_n)_BinarySearch\": algorithm_log_n_binary_search,\n",
        "    \"Sqrt_O(sqrt_n)_PrimalityTest\": algorithm_sqrt_n_primality_test,\n",
        "    \"Linear_O(n)_Sum\": algorithm_linear_sum,\n",
        "    \"Linear_O(n)_ListAppend\": algorithm_linear_list_append,\n",
        "    \"Linear_O(n)_StringConcat\": algorithm_linear_string_concat,\n",
        "    \"Linear_O(n)_DictCreation\": algorithm_linear_dict_creation,\n",
        "    \"Linear_O(n)_FactorialIter\": algorithm_linear_factorial_iter,\n",
        "    \"Linear_O(n)_RecursivePower\": algorithm_linear_recursive_power,\n",
        "    \"N_Log_N_O(n_log_n)_Sort\": algorithm_n_log_n_sort,\n",
        "    \"Quadratic_O(n^2)_NestedLoops\": algorithm_quadratic_loops,\n",
        "    \"Quadratic_O(n^2)_ListSearch\": algorithm_quadratic_list_search,\n",
        "    \"Cubic_O(n^3)_TripleLoops\": algorithm_cubic_loops,\n",
        "    \"Exponential_O(2^n)_Fibonacci\": algorithm_exponential_fib,\n",
        "    \"Factorial_O(n!)_Permutations\": algorithm_factorial_permutations,\n",
        "}\n",
        "\n",
        "print(f\"Loaded {len(algorithms_collection)} algorithms:\\n{list(algorithms_collection.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72bR36upoqLZ",
        "outputId": "33edbd1f-4f6a-46da-a160-47575e33e922"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 15 algorithms:\n",
            "['Constant_O(1)_Formula', 'Logarithmic_O(log_n)_BinarySearch', 'Sqrt_O(sqrt_n)_PrimalityTest', 'Linear_O(n)_Sum', 'Linear_O(n)_ListAppend', 'Linear_O(n)_StringConcat', 'Linear_O(n)_DictCreation', 'Linear_O(n)_FactorialIter', 'Linear_O(n)_RecursivePower', 'N_Log_N_O(n_log_n)_Sort', 'Quadratic_O(n^2)_NestedLoops', 'Quadratic_O(n^2)_ListSearch', 'Cubic_O(n^3)_TripleLoops', 'Exponential_O(2^n)_Fibonacci', 'Factorial_O(n!)_Permutations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoE7JK5fowY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main body: ANALYZER CONFIGURATION AND ENVIRONMENT"
      ],
      "metadata": {
        "id": "jIPjZrdSpOLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*2 + \"\\033[1mANALYZER CONFIGURATION AND ENVIRONMENT\\033[0m\")\n",
        "\n",
        "# 1. Perform the necessary initializations (no changes here)\n",
        "detected_arch = platform.machine().lower()\n",
        "analyzer = EnhancedCostAnalyzer(arch=detected_arch, profile=\"RESEARCH\")\n",
        "profile_info = analyzer.composite_calculator.get_profile_info()\n",
        "\n",
        "config_data = {\n",
        "    \"Detected Architecture\": detected_arch,\n",
        "    \"Available Profiles\": \", \".join(list(PROFILE_WEIGHTS.keys())),\n",
        "    \"Selected Profile\": profile_info['profile'],\n",
        "    \"Profile Description\": profile_info['description'],\n",
        "    \"Profile Weights\": str(profile_info['weights'])\n",
        "}\n",
        "\n",
        "# 3. convert the dictionary items into a list of [key, value] pairs.\n",
        "config_df = pd.DataFrame(\n",
        "    list(config_data.items()),\n",
        "    columns=['Configuration Parameter', 'Value']\n",
        ")\n",
        "\n",
        "# 4. Setting the parameter name as the index makes the table look cleaner.\n",
        "config_df.set_index('Configuration Parameter', inplace=True)\n",
        "display(config_df)\n",
        "\n",
        "########################################################################\n",
        "# --- Enhanced Analysis using Benchmark Suite for proper calibration ---\n",
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*8 + \"\\033[1mENHANCED ALGORITHM ANALYSIS: FULL SUITE SUMMARY\\033[0m\")\n",
        "\n",
        "\n",
        "# 1. Run the entire suite using the 'benchmark_suite' method.\n",
        "# This method first collects all raw results AND THEN updates the\n",
        "# reference values within the analyzer object before calculating scores.\n",
        "#\n",
        "# IMPORTANT: The results inside benchmark_results are calculated AFTER\n",
        "# the reference values have been calibrated on the suite itself.\n",
        "algorithms_for_benchmark = list(algorithms_collection.items())\n",
        "benchmark_results = analyzer.benchmark_suite(algorithms_for_benchmark)\n",
        "\n",
        "# 2. Extract the results dictionary and convert to a DataFrame\n",
        "# The actual results are under the 'results' key.\n",
        "results_data = list(benchmark_results['results'].values())\n",
        "for i, name in enumerate(benchmark_results['results'].keys()):\n",
        "    results_data[i]['Algorithm'] = name\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "\n",
        "# 3. Prepare the DataFrame for display (same as before)\n",
        "display_columns = [\n",
        "    'Algorithm',\n",
        "    'CU',\n",
        "    'EU',\n",
        "    'CO2',\n",
        "    '$',\n",
        "    'CU_normalized',\n",
        "    'EU_normalized',\n",
        "    'CO2_normalized',\n",
        "    '$_normalized',\n",
        "    'SCORE_GRADE',\n",
        "    'EFFICIENCY_RATING',\n",
        "    'COMPOSITE_SCORE'\n",
        "]\n",
        "# Ensure all columns exist before trying to display them\n",
        "# This handles cases where some results might not be generated\n",
        "existing_display_columns = [col for col in display_columns if col in results_df.columns]\n",
        "results_df = results_df[existing_display_columns]\n",
        "\n",
        "# Sort the table by the composite score in descending order\n",
        "results_df = results_df.sort_values(by='COMPOSITE_SCORE', ascending=False)\n",
        "\n",
        "# Set the 'Algorithm' column as the table index\n",
        "results_df.set_index('Algorithm', inplace=True)\n",
        "\n",
        "# Set display options for float numbers\n",
        "pd.options.display.float_format = '{:,.6f}'.format\n",
        "\n",
        "# 4. Print the final, formatted table\n",
        "display(results_df)\n",
        "\n",
        "\n",
        "# 5. (Optional but Recommended) Display the updated reference values\n",
        "print(\"\\n\\n\" + \"-\"*60)\n",
        "print(\"Calibrated Reference Values (used for the scoring above)\")\n",
        "print(\"-\"*60)\n",
        "calibrated_refs = benchmark_results['updated_references']\n",
        "refs_df = pd.DataFrame(calibrated_refs).T # .T transposes the DataFrame\n",
        "display(refs_df)\n",
        "\n",
        "########################################################################\n",
        "# --- Detailed Comparison of All Algorithms Against the Best Performer ---\n",
        "\n",
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*4 + \"\\033[1mDETAILED COMPARISON AGAINST THE BEST PERFORMING ALGORITHM\\033[0m\")\n",
        "\n",
        "# 1. Identify the best algorithm to use as our baseline for comparison.\n",
        "# We get this information from the statistics calculated by the benchmark_suite.\n",
        "baseline_name = benchmark_results['statistics']['best_algorithm']\n",
        "baseline_metrics = benchmark_results['results'][baseline_name]\n",
        "\n",
        "print(f\"\\n[Comparison] Baseline Algorithm (Highest Score): '{baseline_name}'\")\n",
        "\n",
        "# 2. Prepare a list to hold the comparison data for each algorithm.\n",
        "comparison_data = []\n",
        "\n",
        "# Iterate through all algorithm results to compare them against the baseline.\n",
        "for name, current_metrics in benchmark_results['results'].items():\n",
        "    # Calculate the difference in composite score.\n",
        "    score_diff = current_metrics['COMPOSITE_SCORE'] - baseline_metrics['COMPOSITE_SCORE']\n",
        "\n",
        "    # Calculate the percentage change for each raw metric.\n",
        "    # Formula: ((current - baseline) / baseline) * 100\n",
        "    # A positive value means it's \"more expensive\" or \"worse\" than the baseline.\n",
        "    comparison_row = {\n",
        "        'Algorithm': name,\n",
        "        'COMPOSITE_SCORE': current_metrics['COMPOSITE_SCORE'],\n",
        "        'Score_vs_Best': score_diff, # Will be 0 for the best, negative for others.\n",
        "    }\n",
        "\n",
        "    for metric in [\"CU\", \"EU\", \"CO2\", \"$\"]:\n",
        "        current_val = current_metrics[metric]\n",
        "        baseline_val = baseline_metrics[metric]\n",
        "\n",
        "        # Avoid division by zero, though unlikely with this data.\n",
        "        if baseline_val > 0:\n",
        "            percent_change = ((current_val - baseline_val) / baseline_val) * 100\n",
        "        else:\n",
        "            percent_change = float('inf')\n",
        "\n",
        "        comparison_row[f'{metric}_%_vs_Best'] = percent_change\n",
        "\n",
        "    comparison_data.append(comparison_row)\n",
        "\n",
        "# 3. Create the comparison DataFrame.\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df.sort_values(by='COMPOSITE_SCORE', ascending=False, inplace=True)\n",
        "comparison_df.set_index('Algorithm', inplace=True)\n",
        "\n",
        "# 4. Format the DataFrame for better readability using the .style attribute.\n",
        "# This gives us more control over formatting individual columns.\n",
        "formatted_comparison = comparison_df.style.format({\n",
        "    'COMPOSITE_SCORE': '{:.2f}',\n",
        "    'Score_vs_Best': '{:+.2f}', # Add a '+' sign for positive numbers (only the baseline will be 0)\n",
        "    'CU_%_vs_Best': '{:+.2f}%',\n",
        "    'EU_%_vs_Best': '{:+.2f}%',\n",
        "    'CO2_%_vs_Best': '{:+.2f}%',\n",
        "    '$_%_vs_Best': '{:+.2f}%',\n",
        "}).background_gradient(\n",
        "    cmap='Reds', # 'Reds' cmap will highlight larger (worse) percentages in red\n",
        "    subset=['CU_%_vs_Best', 'EU_%_vs_Best', 'CO2_%_vs_Best', '$_%_vs_Best']\n",
        ").bar(\n",
        "    subset=['Score_vs_Best'], # Add bars to show the score difference visually\n",
        "    align='zero',\n",
        "    color=['#d65f5f', '#5fba7d'] # Red for negative, green for positive\n",
        ")\n",
        "\n",
        "# Display the final, styled table.\n",
        "display(formatted_comparison)\n",
        "\n",
        "########################################################################\n",
        "# --- Final Summaries: Statistics, Profile Comparison, and Environment ---\n",
        "\n",
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*5 + \"\\033[1mFINAL SUMMARIES AND CONTEXTUAL ANALYSIS\\033[0m\")\n",
        "\n",
        "# --- Block 1: Benchmark Suite Statistics ---\n",
        "print(\"\\n[Benchmark] Statistical Summary:\")\n",
        "\n",
        "# The statistics are already in a dictionary, perfect for a key-value table.\n",
        "stats_data = benchmark_results['statistics']\n",
        "stats_df = pd.DataFrame(\n",
        "    list(stats_data.items()),\n",
        "    columns=['Statistic', 'Value']\n",
        ")\n",
        "stats_df.set_index('Statistic', inplace=True)\n",
        "\n",
        "# Format float values to 2 decimal places for readability\n",
        "stats_df['Value'] = stats_df['Value'].apply(\n",
        "    lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x\n",
        ")\n",
        "display(stats_df)\n",
        "\n",
        "\n",
        "# --- Block 2: Profile Comparison Analysis ---\n",
        "print(f\"\\n[Profile Comparison] How a single algorithm's score changes based on the active profile: {detected_arch}\")\n",
        "data = []\n",
        "for metric, refs in benchmark_results['updated_references'].items():\n",
        "    data.append({\n",
        "        'metric': metric,\n",
        "        'min': f\"{refs['min']:g}\",\n",
        "        'max': f\"{refs['max']:g}\",\n",
        "        'typical': f\"{refs['typical']:g}\"\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# We'll use a simple, consistent algorithm for this \"what-if\" analysis.\n",
        "test_algorithm_func = algorithms_collection['Constant_O(1)_Formula']\n",
        "\n",
        "print(f\"\\n[Info] Using '{list(algorithms_collection.keys())[0]}' as the test case (current environment).\")\n",
        "\n",
        "profile_comparison_results = []\n",
        "\n",
        "# Iterate through all available profiles defined in PROFILE_WEIGHTS.\n",
        "for profile_name in PROFILE_WEIGHTS.keys():\n",
        "\n",
        "    # 1. Create a temporary, clean analyzer for each profile.\n",
        "    temp_analyzer = EnhancedCostAnalyzer(arch=detected_arch, profile=profile_name)\n",
        "\n",
        "    # 3. Now, analyze our single test function using the fully configured and calibrated analyzer.\n",
        "    # The score will now be calculated relative to the *calibrated* min/max for that profile's logic.\n",
        "    test_result = temp_analyzer.analyze_function(test_algorithm_func)\n",
        "\n",
        "    profile_comparison_results.append({\n",
        "        'Profile': profile_name,\n",
        "        'Composite Score': test_result['COMPOSITE_SCORE'],\n",
        "        'Grade': test_result['SCORE_GRADE']\n",
        "    })\n",
        "\n",
        "# Create and display the DataFrame for the profile comparison.\n",
        "profile_df = pd.DataFrame(profile_comparison_results)\n",
        "profile_df.sort_values(by='Composite Score', ascending=False, inplace=True)\n",
        "profile_df.set_index('Profile', inplace=True)\n",
        "\n",
        "# Display the final table.\n",
        "display(profile_df.style.format({'Composite Score': '{:.2f}'}))\n",
        "\n",
        "\n",
        "\n",
        "# --- Block 3: Environmental Impact Analysis ---\n",
        "# Fetch the carbon intensity value.\n",
        "carbon_intensity = analyzer.fetch_carbon_intensity()\n",
        "print(f\"\\n[Environment] Current Carbon Intensity: {carbon_intensity:g} kgCO2/kWh\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AMAqOBg9sNgw",
        "outputId": "034155c4-0d33-44c1-a5c8-6febfb4a4dfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "######################################################################################################################################################\n",
            "\n",
            "\t\t\u001b[1mANALYZER CONFIGURATION AND ENVIRONMENT\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                     Value\n",
              "Configuration Parameter                                                   \n",
              "Detected Architecture                                               x86_64\n",
              "Available Profiles              RESEARCH, COMMERCIAL, MOBILE, HPC, DEFAULT\n",
              "Selected Profile                                                  RESEARCH\n",
              "Profile Description      Research/Academic - focused on performance wit...\n",
              "Profile Weights             {'CU': 0.4, 'EU': 0.3, 'CO2': 0.25, '$': 0.05}"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-983623b0-a2e8-44a0-b9b7-259a48d025ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Configuration Parameter</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Detected Architecture</th>\n",
              "      <td>x86_64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Available Profiles</th>\n",
              "      <td>RESEARCH, COMMERCIAL, MOBILE, HPC, DEFAULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Selected Profile</th>\n",
              "      <td>RESEARCH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Profile Description</th>\n",
              "      <td>Research/Academic - focused on performance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Profile Weights</th>\n",
              "      <td>{'CU': 0.4, 'EU': 0.3, 'CO2': 0.25, '$': 0.05}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-983623b0-a2e8-44a0-b9b7-259a48d025ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-983623b0-a2e8-44a0-b9b7-259a48d025ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-983623b0-a2e8-44a0-b9b7-259a48d025ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-76ff8e0e-8974-4df0-99df-e51128864209\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76ff8e0e-8974-4df0-99df-e51128864209')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-76ff8e0e-8974-4df0-99df-e51128864209 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "config_df",
              "summary": "{\n  \"name\": \"config_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Configuration Parameter\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Available Profiles\",\n          \"Profile Weights\",\n          \"Selected Profile\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RESEARCH, COMMERCIAL, MOBILE, HPC, DEFAULT\",\n          \"{'CU': 0.4, 'EU': 0.3, 'CO2': 0.25, '$': 0.05}\",\n          \"RESEARCH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "######################################################################################################################################################\n",
            "\n",
            "\t\t\t\t\t\t\t\t\u001b[1mENHANCED ALGORITHM ANALYSIS: FULL SUITE SUMMARY\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          CU       EU      CO2        $  \\\n",
              "Algorithm                                                                 \n",
              "Constant_O(1)_Formula              17.000000 0.001480 0.000498 0.000169   \n",
              "Linear_O(n)_Sum                    25.000000 0.002280 0.000763 0.000249   \n",
              "Linear_O(n)_RecursivePower         27.000000 0.002430 0.000872 0.000269   \n",
              "N_Log_N_O(n_log_n)_Sort            32.000000 0.002930 0.001032 0.000319   \n",
              "Linear_O(n)_ListAppend             35.000000 0.003130 0.001065 0.000349   \n",
              "Linear_O(n)_DictCreation           38.000000 0.003330 0.001098 0.000379   \n",
              "Exponential_O(2^n)_Fibonacci       41.000000 0.003610 0.001175 0.000408   \n",
              "Linear_O(n)_StringConcat           42.000000 0.003680 0.001172 0.000419   \n",
              "Linear_O(n)_FactorialIter          55.000000 0.004760 0.001515 0.000548   \n",
              "Quadratic_O(n^2)_NestedLoops       55.000000 0.004830 0.001579 0.000549   \n",
              "Factorial_O(n!)_Permutations       60.000000 0.005430 0.001901 0.000599   \n",
              "Cubic_O(n^3)_TripleLoops           66.000000 0.005830 0.001922 0.000659   \n",
              "Quadratic_O(n^2)_ListSearch        98.000000 0.008580 0.002748 0.000979   \n",
              "Logarithmic_O(log_n)_BinarySearch 118.000000 0.010250 0.003209 0.001181   \n",
              "Sqrt_O(sqrt_n)_PrimalityTest      129.000000 0.011150 0.003637 0.001285   \n",
              "\n",
              "                                   CU_normalized  EU_normalized  \\\n",
              "Algorithm                                                         \n",
              "Constant_O(1)_Formula                 100.000000     100.000000   \n",
              "Linear_O(n)_Sum                        92.857143      91.726991   \n",
              "Linear_O(n)_RecursivePower             91.071429      90.175801   \n",
              "N_Log_N_O(n_log_n)_Sort                86.607143      85.005171   \n",
              "Linear_O(n)_ListAppend                 83.928571      82.936918   \n",
              "Linear_O(n)_DictCreation               81.250000      80.868666   \n",
              "Exponential_O(2^n)_Fibonacci           78.571429      77.973113   \n",
              "Linear_O(n)_StringConcat               77.678571      77.249224   \n",
              "Linear_O(n)_FactorialIter              66.071429      66.080662   \n",
              "Quadratic_O(n^2)_NestedLoops           66.071429      65.356774   \n",
              "Factorial_O(n!)_Permutations           61.607143      59.152017   \n",
              "Cubic_O(n^3)_TripleLoops               56.250000      55.015512   \n",
              "Quadratic_O(n^2)_ListSearch            27.678571      26.577042   \n",
              "Logarithmic_O(log_n)_BinarySearch       9.821429       9.307135   \n",
              "Sqrt_O(sqrt_n)_PrimalityTest            0.000000       0.000000   \n",
              "\n",
              "                                   CO2_normalized  $_normalized SCORE_GRADE  \\\n",
              "Algorithm                                                                     \n",
              "Constant_O(1)_Formula                  100.000000    100.000000          A+   \n",
              "Linear_O(n)_Sum                         91.557821     92.831541          A+   \n",
              "Linear_O(n)_RecursivePower              88.085378     91.039427          A+   \n",
              "N_Log_N_O(n_log_n)_Sort                 82.988213     86.559140           A   \n",
              "Linear_O(n)_ListAppend                  81.936923     83.870968          A-   \n",
              "Linear_O(n)_DictCreation                80.885632     81.182796          A-   \n",
              "Exponential_O(2^n)_Fibonacci            78.432622     78.584229          B+   \n",
              "Linear_O(n)_StringConcat                78.528194     77.598566          B+   \n",
              "Linear_O(n)_FactorialIter               67.601147     66.039427          B-   \n",
              "Quadratic_O(n^2)_NestedLoops            65.562281     65.949821          B-   \n",
              "Factorial_O(n!)_Permutations            55.304237     61.469534           C   \n",
              "Cubic_O(n^3)_TripleLoops                54.635234     56.093190           C   \n",
              "Quadratic_O(n^2)_ListSearch             28.321121     27.419355           F   \n",
              "Logarithmic_O(log_n)_BinarySearch       13.634916      9.318996           F   \n",
              "Sqrt_O(sqrt_n)_PrimalityTest             0.000000      0.000000           F   \n",
              "\n",
              "                                  EFFICIENCY_RATING  COMPOSITE_SCORE  \n",
              "Algorithm                                                             \n",
              "Constant_O(1)_Formula                     Excellent       100.000000  \n",
              "Linear_O(n)_Sum                           Excellent        92.191987  \n",
              "Linear_O(n)_RecursivePower                Excellent        90.054628  \n",
              "N_Log_N_O(n_log_n)_Sort                   Excellent        85.219419  \n",
              "Linear_O(n)_ListAppend                         Good        83.130283  \n",
              "Linear_O(n)_DictCreation                       Good        81.041148  \n",
              "Exponential_O(2^n)_Fibonacci                   Good        78.357872  \n",
              "Linear_O(n)_StringConcat                       Good        77.758173  \n",
              "Linear_O(n)_FactorialIter                   Average        66.455028  \n",
              "Quadratic_O(n^2)_NestedLoops                Average        65.723665  \n",
              "Factorial_O(n!)_Permutations                Average        59.287998  \n",
              "Cubic_O(n^3)_TripleLoops                    Average        55.468122  \n",
              "Quadratic_O(n^2)_ListSearch                    Poor        27.495789  \n",
              "Logarithmic_O(log_n)_BinarySearch              Poor        10.595391  \n",
              "Sqrt_O(sqrt_n)_PrimalityTest                   Poor         0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5fa10b0-a5f6-4383-9119-dfb3ea641a18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CU</th>\n",
              "      <th>EU</th>\n",
              "      <th>CO2</th>\n",
              "      <th>$</th>\n",
              "      <th>CU_normalized</th>\n",
              "      <th>EU_normalized</th>\n",
              "      <th>CO2_normalized</th>\n",
              "      <th>$_normalized</th>\n",
              "      <th>SCORE_GRADE</th>\n",
              "      <th>EFFICIENCY_RATING</th>\n",
              "      <th>COMPOSITE_SCORE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Algorithm</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Constant_O(1)_Formula</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.001480</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>A+</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear_O(n)_Sum</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>92.857143</td>\n",
              "      <td>91.726991</td>\n",
              "      <td>91.557821</td>\n",
              "      <td>92.831541</td>\n",
              "      <td>A+</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>92.191987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear_O(n)_RecursivePower</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.000872</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>91.071429</td>\n",
              "      <td>90.175801</td>\n",
              "      <td>88.085378</td>\n",
              "      <td>91.039427</td>\n",
              "      <td>A+</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>90.054628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N_Log_N_O(n_log_n)_Sort</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>86.607143</td>\n",
              "      <td>85.005171</td>\n",
              "      <td>82.988213</td>\n",
              "      <td>86.559140</td>\n",
              "      <td>A</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>85.219419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear_O(n)_ListAppend</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>83.928571</td>\n",
              "      <td>82.936918</td>\n",
              "      <td>81.936923</td>\n",
              "      <td>83.870968</td>\n",
              "      <td>A-</td>\n",
              "      <td>Good</td>\n",
              "      <td>83.130283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear_O(n)_DictCreation</th>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.003330</td>\n",
              "      <td>0.001098</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>80.868666</td>\n",
              "      <td>80.885632</td>\n",
              "      <td>81.182796</td>\n",
              "      <td>A-</td>\n",
              "      <td>Good</td>\n",
              "      <td>81.041148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exponential_O(2^n)_Fibonacci</th>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.003610</td>\n",
              "      <td>0.001175</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>78.571429</td>\n",
              "      <td>77.973113</td>\n",
              "      <td>78.432622</td>\n",
              "      <td>78.584229</td>\n",
              "      <td>B+</td>\n",
              "      <td>Good</td>\n",
              "      <td>78.357872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear_O(n)_StringConcat</th>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.001172</td>\n",
              "      <td>0.000419</td>\n",
              "      <td>77.678571</td>\n",
              "      <td>77.249224</td>\n",
              "      <td>78.528194</td>\n",
              "      <td>77.598566</td>\n",
              "      <td>B+</td>\n",
              "      <td>Good</td>\n",
              "      <td>77.758173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear_O(n)_FactorialIter</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.004760</td>\n",
              "      <td>0.001515</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>66.071429</td>\n",
              "      <td>66.080662</td>\n",
              "      <td>67.601147</td>\n",
              "      <td>66.039427</td>\n",
              "      <td>B-</td>\n",
              "      <td>Average</td>\n",
              "      <td>66.455028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quadratic_O(n^2)_NestedLoops</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.004830</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>66.071429</td>\n",
              "      <td>65.356774</td>\n",
              "      <td>65.562281</td>\n",
              "      <td>65.949821</td>\n",
              "      <td>B-</td>\n",
              "      <td>Average</td>\n",
              "      <td>65.723665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Factorial_O(n!)_Permutations</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.005430</td>\n",
              "      <td>0.001901</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>61.607143</td>\n",
              "      <td>59.152017</td>\n",
              "      <td>55.304237</td>\n",
              "      <td>61.469534</td>\n",
              "      <td>C</td>\n",
              "      <td>Average</td>\n",
              "      <td>59.287998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cubic_O(n^3)_TripleLoops</th>\n",
              "      <td>66.000000</td>\n",
              "      <td>0.005830</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>56.250000</td>\n",
              "      <td>55.015512</td>\n",
              "      <td>54.635234</td>\n",
              "      <td>56.093190</td>\n",
              "      <td>C</td>\n",
              "      <td>Average</td>\n",
              "      <td>55.468122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quadratic_O(n^2)_ListSearch</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.008580</td>\n",
              "      <td>0.002748</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>27.678571</td>\n",
              "      <td>26.577042</td>\n",
              "      <td>28.321121</td>\n",
              "      <td>27.419355</td>\n",
              "      <td>F</td>\n",
              "      <td>Poor</td>\n",
              "      <td>27.495789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logarithmic_O(log_n)_BinarySearch</th>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.010250</td>\n",
              "      <td>0.003209</td>\n",
              "      <td>0.001181</td>\n",
              "      <td>9.821429</td>\n",
              "      <td>9.307135</td>\n",
              "      <td>13.634916</td>\n",
              "      <td>9.318996</td>\n",
              "      <td>F</td>\n",
              "      <td>Poor</td>\n",
              "      <td>10.595391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sqrt_O(sqrt_n)_PrimalityTest</th>\n",
              "      <td>129.000000</td>\n",
              "      <td>0.011150</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>F</td>\n",
              "      <td>Poor</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5fa10b0-a5f6-4383-9119-dfb3ea641a18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5fa10b0-a5f6-4383-9119-dfb3ea641a18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5fa10b0-a5f6-4383-9119-dfb3ea641a18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df9c81eb-d61c-4fe8-be20-b8d98cb3f2c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df9c81eb-d61c-4fe8-be20-b8d98cb3f2c7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df9c81eb-d61c-4fe8-be20-b8d98cb3f2c7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Algorithm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Quadratic_O(n^2)_NestedLoops\",\n          \"Cubic_O(n^3)_TripleLoops\",\n          \"Constant_O(1)_Formula\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.95346956112284,\n        \"min\": 17.0,\n        \"max\": 129.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          60.0,\n          98.0,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0029238909171236368,\n        \"min\": 0.0014800000000000002,\n        \"max\": 0.011150000000000002,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.004830000000000003,\n          0.005830000000000004,\n          0.0014800000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009229385368794304,\n        \"min\": 0.0004980000000000001,\n        \"max\": 0.003637000000000002,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.0015790000000000003,\n          0.001922,\n          0.0004980000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"$\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00033921586047825074,\n        \"min\": 0.00016900000000000002,\n        \"max\": 0.0012850000000000006,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.0005490000000000002,\n          0.0006590000000000002,\n          0.00016900000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CU_normalized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.315597822431112,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          61.60714285714286,\n          27.67857142857143,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EU_normalized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.23672096301589,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          65.35677352637019,\n          55.01551189245085,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2_normalized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.402310827633954,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          65.56228098120422,\n          54.63523415100353,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"$_normalized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.395686422782312,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          65.94982078853047,\n          56.09318996415771,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCORE_GRADE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"A+\",\n          \"A\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EFFICIENCY_RATING\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Good\",\n          \"Poor\",\n          \"Excellent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COMPOSITE_SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.05401775776517,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          65.72366477121007,\n          55.468121603694016,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Calibrated Reference Values (used for the scoring above)\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          min        max   typical\n",
              "CU  17.000000 129.000000 42.000000\n",
              "EU   0.001480   0.011150  0.003680\n",
              "CO2  0.000498   0.003637  0.001175\n",
              "$    0.000169   0.001285  0.000419"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce68365b-ac45-406a-9ef4-14a83142c3b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>typical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CU</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EU</th>\n",
              "      <td>0.001480</td>\n",
              "      <td>0.011150</td>\n",
              "      <td>0.003680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CO2</th>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>0.001175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>$</th>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.000419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce68365b-ac45-406a-9ef4-14a83142c3b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce68365b-ac45-406a-9ef4-14a83142c3b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce68365b-ac45-406a-9ef4-14a83142c3b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-095f3094-ed7e-48ae-8c4c-f1f83d85ec23\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-095f3094-ed7e-48ae-8c4c-f1f83d85ec23')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-095f3094-ed7e-48ae-8c4c-f1f83d85ec23 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "refs_df",
              "summary": "{\n  \"name\": \"refs_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.499642184911133,\n        \"min\": 0.00016900000000000002,\n        \"max\": 17.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0014800000000000002,\n          0.00016900000000000002,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.49732147054428,\n        \"min\": 0.0012850000000000006,\n        \"max\": 129.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.011150000000000002,\n          0.0012850000000000006,\n          129.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"typical\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.999121046247126,\n        \"min\": 0.00041900000000000016,\n        \"max\": 42.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.00368,\n          0.00041900000000000016,\n          42.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "######################################################################################################################################################\n",
            "\n",
            "\t\t\t\t\u001b[1mDETAILED COMPARISON AGAINST THE BEST PERFORMING ALGORITHM\u001b[0m\n",
            "\n",
            "[Comparison] Baseline Algorithm (Highest Score): 'Constant_O(1)_Formula'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a9ea7eeb0d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_1a736_row0_col1 {\n",
              "  width: 10em;\n",
              "}\n",
              "#T_1a736_row0_col2, #T_1a736_row0_col3, #T_1a736_row0_col4, #T_1a736_row0_col5 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row1_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 46.1%, #d65f5f 46.1%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row1_col2, #T_1a736_row1_col5 {\n",
              "  background-color: #fee9df;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row1_col3, #T_1a736_row1_col4 {\n",
              "  background-color: #fee7dc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row2_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 45.0%, #d65f5f 45.0%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row2_col2, #T_1a736_row2_col5 {\n",
              "  background-color: #fee7db;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row2_col3 {\n",
              "  background-color: #fee5d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row2_col4 {\n",
              "  background-color: #fee1d4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row3_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 42.6%, #d65f5f 42.6%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row3_col2, #T_1a736_row3_col5 {\n",
              "  background-color: #fedecf;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row3_col3 {\n",
              "  background-color: #fed9c9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row3_col4, #T_1a736_row4_col3 {\n",
              "  background-color: #fdd3c1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row4_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 41.6%, #d65f5f 41.6%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row4_col2, #T_1a736_row4_col5 {\n",
              "  background-color: #fdd5c4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row4_col4 {\n",
              "  background-color: #fdd0bc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row5_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 40.5%, #d65f5f 40.5%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row5_col2, #T_1a736_row5_col3, #T_1a736_row5_col4, #T_1a736_row5_col5 {\n",
              "  background-color: #fdcdb9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row6_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 39.2%, #d65f5f 39.2%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row6_col2, #T_1a736_row6_col5, #T_1a736_row7_col4 {\n",
              "  background-color: #fdc6b0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row6_col3 {\n",
              "  background-color: #fcc4ad;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row6_col4 {\n",
              "  background-color: #fdc5ae;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row7_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 38.9%, #d65f5f 38.9%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row7_col2, #T_1a736_row7_col5 {\n",
              "  background-color: #fcc3ab;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row7_col3 {\n",
              "  background-color: #fcc2aa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row8_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 33.2%, #d65f5f 33.2%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row8_col2, #T_1a736_row8_col3, #T_1a736_row8_col5, #T_1a736_row9_col2 {\n",
              "  background-color: #fc9e80;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row8_col4 {\n",
              "  background-color: #fca486;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row9_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 32.9%, #d65f5f 32.9%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row9_col3, #T_1a736_row9_col4 {\n",
              "  background-color: #fc9c7d;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row9_col5 {\n",
              "  background-color: #fc9d7f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row10_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 29.6%, #d65f5f 29.6%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row10_col2, #T_1a736_row10_col5 {\n",
              "  background-color: #fc8f6f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_1a736_row10_col3 {\n",
              "  background-color: #fc8767;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row10_col4 {\n",
              "  background-color: #fb7b5b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row11_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 27.7%, #d65f5f 27.7%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row11_col2, #T_1a736_row11_col5 {\n",
              "  background-color: #fb7d5d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row11_col3 {\n",
              "  background-color: #fb7a5a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row11_col4 {\n",
              "  background-color: #fb7858;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row12_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 13.7%, #d65f5f 13.7%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row12_col2, #T_1a736_row12_col5 {\n",
              "  background-color: #d21f20;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row12_col3 {\n",
              "  background-color: #d01d1f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row12_col4 {\n",
              "  background-color: #d42121;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row13_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, transparent 5.3%, #d65f5f 5.3%, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row13_col2 {\n",
              "  background-color: #980c13;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row13_col3, #T_1a736_row13_col5 {\n",
              "  background-color: #940b13;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row13_col4 {\n",
              "  background-color: #a81016;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_1a736_row14_col1 {\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);\n",
              "}\n",
              "#T_1a736_row14_col2, #T_1a736_row14_col3, #T_1a736_row14_col4, #T_1a736_row14_col5 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_1a736\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_1a736_level0_col0\" class=\"col_heading level0 col0\" >COMPOSITE_SCORE</th>\n",
              "      <th id=\"T_1a736_level0_col1\" class=\"col_heading level0 col1\" >Score_vs_Best</th>\n",
              "      <th id=\"T_1a736_level0_col2\" class=\"col_heading level0 col2\" >CU_%_vs_Best</th>\n",
              "      <th id=\"T_1a736_level0_col3\" class=\"col_heading level0 col3\" >EU_%_vs_Best</th>\n",
              "      <th id=\"T_1a736_level0_col4\" class=\"col_heading level0 col4\" >CO2_%_vs_Best</th>\n",
              "      <th id=\"T_1a736_level0_col5\" class=\"col_heading level0 col5\" >$_%_vs_Best</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Algorithm</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "      <th class=\"blank col4\" >&nbsp;</th>\n",
              "      <th class=\"blank col5\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row0\" class=\"row_heading level0 row0\" >Constant_O(1)_Formula</th>\n",
              "      <td id=\"T_1a736_row0_col0\" class=\"data row0 col0\" >100.00</td>\n",
              "      <td id=\"T_1a736_row0_col1\" class=\"data row0 col1\" >+0.00</td>\n",
              "      <td id=\"T_1a736_row0_col2\" class=\"data row0 col2\" >+0.00%</td>\n",
              "      <td id=\"T_1a736_row0_col3\" class=\"data row0 col3\" >+0.00%</td>\n",
              "      <td id=\"T_1a736_row0_col4\" class=\"data row0 col4\" >+0.00%</td>\n",
              "      <td id=\"T_1a736_row0_col5\" class=\"data row0 col5\" >+0.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row1\" class=\"row_heading level0 row1\" >Linear_O(n)_Sum</th>\n",
              "      <td id=\"T_1a736_row1_col0\" class=\"data row1 col0\" >92.19</td>\n",
              "      <td id=\"T_1a736_row1_col1\" class=\"data row1 col1\" >-7.81</td>\n",
              "      <td id=\"T_1a736_row1_col2\" class=\"data row1 col2\" >+47.06%</td>\n",
              "      <td id=\"T_1a736_row1_col3\" class=\"data row1 col3\" >+54.05%</td>\n",
              "      <td id=\"T_1a736_row1_col4\" class=\"data row1 col4\" >+53.21%</td>\n",
              "      <td id=\"T_1a736_row1_col5\" class=\"data row1 col5\" >+47.34%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row2\" class=\"row_heading level0 row2\" >Linear_O(n)_RecursivePower</th>\n",
              "      <td id=\"T_1a736_row2_col0\" class=\"data row2 col0\" >90.05</td>\n",
              "      <td id=\"T_1a736_row2_col1\" class=\"data row2 col1\" >-9.95</td>\n",
              "      <td id=\"T_1a736_row2_col2\" class=\"data row2 col2\" >+58.82%</td>\n",
              "      <td id=\"T_1a736_row2_col3\" class=\"data row2 col3\" >+64.19%</td>\n",
              "      <td id=\"T_1a736_row2_col4\" class=\"data row2 col4\" >+75.10%</td>\n",
              "      <td id=\"T_1a736_row2_col5\" class=\"data row2 col5\" >+59.17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row3\" class=\"row_heading level0 row3\" >N_Log_N_O(n_log_n)_Sort</th>\n",
              "      <td id=\"T_1a736_row3_col0\" class=\"data row3 col0\" >85.22</td>\n",
              "      <td id=\"T_1a736_row3_col1\" class=\"data row3 col1\" >-14.78</td>\n",
              "      <td id=\"T_1a736_row3_col2\" class=\"data row3 col2\" >+88.24%</td>\n",
              "      <td id=\"T_1a736_row3_col3\" class=\"data row3 col3\" >+97.97%</td>\n",
              "      <td id=\"T_1a736_row3_col4\" class=\"data row3 col4\" >+107.23%</td>\n",
              "      <td id=\"T_1a736_row3_col5\" class=\"data row3 col5\" >+88.76%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row4\" class=\"row_heading level0 row4\" >Linear_O(n)_ListAppend</th>\n",
              "      <td id=\"T_1a736_row4_col0\" class=\"data row4 col0\" >83.13</td>\n",
              "      <td id=\"T_1a736_row4_col1\" class=\"data row4 col1\" >-16.87</td>\n",
              "      <td id=\"T_1a736_row4_col2\" class=\"data row4 col2\" >+105.88%</td>\n",
              "      <td id=\"T_1a736_row4_col3\" class=\"data row4 col3\" >+111.49%</td>\n",
              "      <td id=\"T_1a736_row4_col4\" class=\"data row4 col4\" >+113.86%</td>\n",
              "      <td id=\"T_1a736_row4_col5\" class=\"data row4 col5\" >+106.51%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row5\" class=\"row_heading level0 row5\" >Linear_O(n)_DictCreation</th>\n",
              "      <td id=\"T_1a736_row5_col0\" class=\"data row5 col0\" >81.04</td>\n",
              "      <td id=\"T_1a736_row5_col1\" class=\"data row5 col1\" >-18.96</td>\n",
              "      <td id=\"T_1a736_row5_col2\" class=\"data row5 col2\" >+123.53%</td>\n",
              "      <td id=\"T_1a736_row5_col3\" class=\"data row5 col3\" >+125.00%</td>\n",
              "      <td id=\"T_1a736_row5_col4\" class=\"data row5 col4\" >+120.48%</td>\n",
              "      <td id=\"T_1a736_row5_col5\" class=\"data row5 col5\" >+124.26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row6\" class=\"row_heading level0 row6\" >Exponential_O(2^n)_Fibonacci</th>\n",
              "      <td id=\"T_1a736_row6_col0\" class=\"data row6 col0\" >78.36</td>\n",
              "      <td id=\"T_1a736_row6_col1\" class=\"data row6 col1\" >-21.64</td>\n",
              "      <td id=\"T_1a736_row6_col2\" class=\"data row6 col2\" >+141.18%</td>\n",
              "      <td id=\"T_1a736_row6_col3\" class=\"data row6 col3\" >+143.92%</td>\n",
              "      <td id=\"T_1a736_row6_col4\" class=\"data row6 col4\" >+135.94%</td>\n",
              "      <td id=\"T_1a736_row6_col5\" class=\"data row6 col5\" >+141.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row7\" class=\"row_heading level0 row7\" >Linear_O(n)_StringConcat</th>\n",
              "      <td id=\"T_1a736_row7_col0\" class=\"data row7 col0\" >77.76</td>\n",
              "      <td id=\"T_1a736_row7_col1\" class=\"data row7 col1\" >-22.24</td>\n",
              "      <td id=\"T_1a736_row7_col2\" class=\"data row7 col2\" >+147.06%</td>\n",
              "      <td id=\"T_1a736_row7_col3\" class=\"data row7 col3\" >+148.65%</td>\n",
              "      <td id=\"T_1a736_row7_col4\" class=\"data row7 col4\" >+135.34%</td>\n",
              "      <td id=\"T_1a736_row7_col5\" class=\"data row7 col5\" >+147.93%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row8\" class=\"row_heading level0 row8\" >Linear_O(n)_FactorialIter</th>\n",
              "      <td id=\"T_1a736_row8_col0\" class=\"data row8 col0\" >66.46</td>\n",
              "      <td id=\"T_1a736_row8_col1\" class=\"data row8 col1\" >-33.54</td>\n",
              "      <td id=\"T_1a736_row8_col2\" class=\"data row8 col2\" >+223.53%</td>\n",
              "      <td id=\"T_1a736_row8_col3\" class=\"data row8 col3\" >+221.62%</td>\n",
              "      <td id=\"T_1a736_row8_col4\" class=\"data row8 col4\" >+204.22%</td>\n",
              "      <td id=\"T_1a736_row8_col5\" class=\"data row8 col5\" >+224.26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row9\" class=\"row_heading level0 row9\" >Quadratic_O(n^2)_NestedLoops</th>\n",
              "      <td id=\"T_1a736_row9_col0\" class=\"data row9 col0\" >65.72</td>\n",
              "      <td id=\"T_1a736_row9_col1\" class=\"data row9 col1\" >-34.28</td>\n",
              "      <td id=\"T_1a736_row9_col2\" class=\"data row9 col2\" >+223.53%</td>\n",
              "      <td id=\"T_1a736_row9_col3\" class=\"data row9 col3\" >+226.35%</td>\n",
              "      <td id=\"T_1a736_row9_col4\" class=\"data row9 col4\" >+217.07%</td>\n",
              "      <td id=\"T_1a736_row9_col5\" class=\"data row9 col5\" >+224.85%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row10\" class=\"row_heading level0 row10\" >Factorial_O(n!)_Permutations</th>\n",
              "      <td id=\"T_1a736_row10_col0\" class=\"data row10 col0\" >59.29</td>\n",
              "      <td id=\"T_1a736_row10_col1\" class=\"data row10 col1\" >-40.71</td>\n",
              "      <td id=\"T_1a736_row10_col2\" class=\"data row10 col2\" >+252.94%</td>\n",
              "      <td id=\"T_1a736_row10_col3\" class=\"data row10 col3\" >+266.89%</td>\n",
              "      <td id=\"T_1a736_row10_col4\" class=\"data row10 col4\" >+281.73%</td>\n",
              "      <td id=\"T_1a736_row10_col5\" class=\"data row10 col5\" >+254.44%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row11\" class=\"row_heading level0 row11\" >Cubic_O(n^3)_TripleLoops</th>\n",
              "      <td id=\"T_1a736_row11_col0\" class=\"data row11 col0\" >55.47</td>\n",
              "      <td id=\"T_1a736_row11_col1\" class=\"data row11 col1\" >-44.53</td>\n",
              "      <td id=\"T_1a736_row11_col2\" class=\"data row11 col2\" >+288.24%</td>\n",
              "      <td id=\"T_1a736_row11_col3\" class=\"data row11 col3\" >+293.92%</td>\n",
              "      <td id=\"T_1a736_row11_col4\" class=\"data row11 col4\" >+285.94%</td>\n",
              "      <td id=\"T_1a736_row11_col5\" class=\"data row11 col5\" >+289.94%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row12\" class=\"row_heading level0 row12\" >Quadratic_O(n^2)_ListSearch</th>\n",
              "      <td id=\"T_1a736_row12_col0\" class=\"data row12 col0\" >27.50</td>\n",
              "      <td id=\"T_1a736_row12_col1\" class=\"data row12 col1\" >-72.50</td>\n",
              "      <td id=\"T_1a736_row12_col2\" class=\"data row12 col2\" >+476.47%</td>\n",
              "      <td id=\"T_1a736_row12_col3\" class=\"data row12 col3\" >+479.73%</td>\n",
              "      <td id=\"T_1a736_row12_col4\" class=\"data row12 col4\" >+451.81%</td>\n",
              "      <td id=\"T_1a736_row12_col5\" class=\"data row12 col5\" >+479.29%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row13\" class=\"row_heading level0 row13\" >Logarithmic_O(log_n)_BinarySearch</th>\n",
              "      <td id=\"T_1a736_row13_col0\" class=\"data row13 col0\" >10.60</td>\n",
              "      <td id=\"T_1a736_row13_col1\" class=\"data row13 col1\" >-89.40</td>\n",
              "      <td id=\"T_1a736_row13_col2\" class=\"data row13 col2\" >+594.12%</td>\n",
              "      <td id=\"T_1a736_row13_col3\" class=\"data row13 col3\" >+592.57%</td>\n",
              "      <td id=\"T_1a736_row13_col4\" class=\"data row13 col4\" >+544.38%</td>\n",
              "      <td id=\"T_1a736_row13_col5\" class=\"data row13 col5\" >+598.82%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1a736_level0_row14\" class=\"row_heading level0 row14\" >Sqrt_O(sqrt_n)_PrimalityTest</th>\n",
              "      <td id=\"T_1a736_row14_col0\" class=\"data row14 col0\" >0.00</td>\n",
              "      <td id=\"T_1a736_row14_col1\" class=\"data row14 col1\" >-100.00</td>\n",
              "      <td id=\"T_1a736_row14_col2\" class=\"data row14 col2\" >+658.82%</td>\n",
              "      <td id=\"T_1a736_row14_col3\" class=\"data row14 col3\" >+653.38%</td>\n",
              "      <td id=\"T_1a736_row14_col4\" class=\"data row14 col4\" >+630.32%</td>\n",
              "      <td id=\"T_1a736_row14_col5\" class=\"data row14 col5\" >+660.36%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "######################################################################################################################################################\n",
            "\n",
            "\t\t\t\t\t\u001b[1mFINAL SUMMARIES AND CONTEXTUAL ANALYSIS\u001b[0m\n",
            "\n",
            "[Benchmark] Statistical Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Value\n",
              "Statistic                                            \n",
              "best_algorithm                  Constant_O(1)_Formula\n",
              "worst_algorithm          Sqrt_O(sqrt_n)_PrimalityTest\n",
              "average_composite_score                         64.85\n",
              "median_composite_score                          77.76\n",
              "composite_score_std                             30.05\n",
              "score_range                                    100.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-799acec0-087d-4a86-b906-4b474ba2cb3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Statistic</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>best_algorithm</th>\n",
              "      <td>Constant_O(1)_Formula</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst_algorithm</th>\n",
              "      <td>Sqrt_O(sqrt_n)_PrimalityTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_composite_score</th>\n",
              "      <td>64.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median_composite_score</th>\n",
              "      <td>77.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>composite_score_std</th>\n",
              "      <td>30.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>score_range</th>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-799acec0-087d-4a86-b906-4b474ba2cb3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-799acec0-087d-4a86-b906-4b474ba2cb3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-799acec0-087d-4a86-b906-4b474ba2cb3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6761865b-bad8-4363-ab89-f2a9477518ef\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6761865b-bad8-4363-ab89-f2a9477518ef')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6761865b-bad8-4363-ab89-f2a9477518ef button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stats_df",
              "summary": "{\n  \"name\": \"stats_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Statistic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"best_algorithm\",\n          \"worst_algorithm\",\n          \"score_range\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Constant_O(1)_Formula\",\n          \"Sqrt_O(sqrt_n)_PrimalityTest\",\n          \"100.00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Profile Comparison] How a single algorithm's score changes based on the active profile: x86_64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  metric       min       max   typical\n",
              "0     CU        17       129        42\n",
              "1     EU   0.00148   0.01115   0.00368\n",
              "2    CO2  0.000498  0.003637  0.001175\n",
              "3      $  0.000169  0.001285  0.000419"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02ee3c62-4614-4cb6-becf-8638ebb4d82b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>typical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CU</td>\n",
              "      <td>17</td>\n",
              "      <td>129</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EU</td>\n",
              "      <td>0.00148</td>\n",
              "      <td>0.01115</td>\n",
              "      <td>0.00368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CO2</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>0.001175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>$</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.000419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02ee3c62-4614-4cb6-becf-8638ebb4d82b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02ee3c62-4614-4cb6-becf-8638ebb4d82b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02ee3c62-4614-4cb6-becf-8638ebb4d82b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a1906077-84a8-4d33-a7ed-1d76f113a3e4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1906077-84a8-4d33-a7ed-1d76f113a3e4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a1906077-84a8-4d33-a7ed-1d76f113a3e4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"EU\",\n          \"$\",\n          \"CU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.00148\",\n          \"0.000169\",\n          \"17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.01115\",\n          \"0.001285\",\n          \"129\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"typical\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.00368\",\n          \"0.000419\",\n          \"42\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Info] Using 'Constant_O(1)_Formula' as the test case (current environment).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a9ea8217650>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_69463\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_69463_level0_col0\" class=\"col_heading level0 col0\" >Composite Score</th>\n",
              "      <th id=\"T_69463_level0_col1\" class=\"col_heading level0 col1\" >Grade</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Profile</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_69463_level0_row0\" class=\"row_heading level0 row0\" >MOBILE</th>\n",
              "      <td id=\"T_69463_row0_col0\" class=\"data row0 col0\" >99.57</td>\n",
              "      <td id=\"T_69463_row0_col1\" class=\"data row0 col1\" >A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69463_level0_row1\" class=\"row_heading level0 row1\" >COMMERCIAL</th>\n",
              "      <td id=\"T_69463_row1_col0\" class=\"data row1 col0\" >99.46</td>\n",
              "      <td id=\"T_69463_row1_col1\" class=\"data row1 col1\" >A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69463_level0_row2\" class=\"row_heading level0 row2\" >DEFAULT</th>\n",
              "      <td id=\"T_69463_row2_col0\" class=\"data row2 col0\" >99.40</td>\n",
              "      <td id=\"T_69463_row2_col1\" class=\"data row2 col1\" >A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69463_level0_row3\" class=\"row_heading level0 row3\" >RESEARCH</th>\n",
              "      <td id=\"T_69463_row3_col0\" class=\"data row3 col0\" >99.33</td>\n",
              "      <td id=\"T_69463_row3_col1\" class=\"data row3 col1\" >A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69463_level0_row4\" class=\"row_heading level0 row4\" >HPC</th>\n",
              "      <td id=\"T_69463_row4_col0\" class=\"data row4 col0\" >99.18</td>\n",
              "      <td id=\"T_69463_row4_col1\" class=\"data row4 col1\" >A+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Environment] Current Carbon Intensity: 0.087 kgCO2/kWh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main body: REPORTING AND SAVING RESULTS"
      ],
      "metadata": {
        "id": "ZzVrw5HngZT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVING_FLAG = False\n",
        "# --- Reporting and Saving ---\n",
        "\n",
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*8 + \"\\033[1mREPORTING AND SAVING RESULTS\\033[0m\")\n",
        "\n",
        "# --- 1. Generate All Data and Visualizations (always happens) ---\n",
        "\n",
        "# a) Generate the summary chart for all algorithms\n",
        "print(\"\\n[Chart] Generating overall benchmark summary chart...\")\n",
        "create_benchmark_summary_chart(benchmark_results, DEFAULT_REPORT_DIR)\n",
        "print(\"  > Chart is displayed above.\")\n",
        "\n",
        "# --- Generate Comparison Charts for All Algorithms ---\n",
        "print(\"\\n[Chart] Generating comparison charts for each algorithm vs. the best...\")\n",
        "\n",
        "# 1. Identify the baseline algorithm (the best one).\n",
        "best_algo_name = benchmark_results['statistics']['best_algorithm']\n",
        "best_algo_results = benchmark_results['results'][best_algo_name]\n",
        "print(f\"  > Baseline for comparison is '{best_algo_name}'.\")\n",
        "\n",
        "# 2. IMPORTANT: Create the main reports directory BEFORE the loop.\n",
        "# The REPORT_DIR variable comes from the main script context (e.g., \"enhanced_reports\").\n",
        "os.makedirs(DEFAULT_REPORT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. Loop through all algorithms and generate a chart for each one.\n",
        "for current_algo_name, current_algo_results in benchmark_results['results'].items():\n",
        "\n",
        "    if current_algo_name == best_algo_name:\n",
        "        continue\n",
        "\n",
        "    safe_current_name = make_safe_filename(current_algo_name)\n",
        "    safe_best_name = make_safe_filename(best_algo_name)\n",
        "    chart_filename = f\"comparison_{safe_current_name}_vs_{safe_best_name}.png\"\n",
        "\n",
        "    # Construct the full, final path for the image file.\n",
        "    output_filepath = os.path.join(DEFAULT_REPORT_DIR, chart_filename)\n",
        "\n",
        "    print(f\"  > Generating chart: {chart_filename}\")\n",
        "\n",
        "    # Call the updated chart function with the full file path.\n",
        "    create_enhanced_comparison_chart(\n",
        "        result1=best_algo_results,\n",
        "        result2=current_algo_results,\n",
        "        output_filepath=DEFAULT_REPORT_DIR, # Pass the full path\n",
        "        names=(best_algo_name, current_algo_name)\n",
        "    )\n",
        "\n",
        "print(\"  > All comparison charts have been generated and displayed.\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Generate and Display Comprehensive Summary Report ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*110)\n",
        "print(\"\\t\"*5 + \"\\033[1mCOMPREHENSIVE SUMMARY REPORT\\033[0m\")\n",
        "print(\"=\"*110)\n",
        "\n",
        "# 1. Prepare all the data components (no change here)\n",
        "best_algo_name = benchmark_results['statistics']['best_algorithm']\n",
        "worst_algo_name = benchmark_results['statistics']['worst_algorithm']\n",
        "best_algo_results = benchmark_results['results'][best_algo_name]\n",
        "worst_algo_results = benchmark_results['results'][worst_algo_name]\n",
        "\n",
        "# 2. Create the summary_report dictionary as before\n",
        "summary_report = {\n",
        "    \"analysis_timestamp\": platform.platform(),\n",
        "    \"architecture\": detected_arch,\n",
        "    \"profile_used\": profile_info,\n",
        "    \"benchmark_summary_stats\": benchmark_results[\"statistics\"],\n",
        "    \"best_algorithm_details\": best_algo_results,\n",
        "    \"worst_algorithm_details\": worst_algo_results,\n",
        "    \"recommendations\": generate_recommendations(benchmark_results, profile_info)\n",
        "}\n",
        "\n",
        "# 3. Flatten the complex dictionary into a list of [key, value] pairs for the DataFrame\n",
        "report_data_list = []\n",
        "\n",
        "# a) Add top-level info\n",
        "report_data_list.append(['Analysis Timestamp', summary_report['analysis_timestamp']])\n",
        "report_data_list.append(['Architecture', summary_report['architecture']])\n",
        "\n",
        "# b) Unroll the 'profile_used' dictionary\n",
        "for key, value in summary_report['profile_used'].items():\n",
        "    # Make keys more descriptive, e.g., \"Profile - Description\"\n",
        "    descriptive_key = f\"Profile - {key.replace('_', ' ').capitalize()}\"\n",
        "    report_data_list.append([descriptive_key, str(value)])\n",
        "\n",
        "# c) Unroll the 'benchmark_summary_stats' dictionary\n",
        "for key, value in summary_report['benchmark_summary_stats'].items():\n",
        "    descriptive_key = f\"Stat - {key.replace('_', ' ').title()}\"\n",
        "    # Format numbers for better display\n",
        "    formatted_value = f\"{value:.2f}\" if isinstance(value, float) else value\n",
        "    report_data_list.append([descriptive_key, formatted_value])\n",
        "\n",
        "# d) Unroll the 'recommendations' list\n",
        "for i, rec_text in enumerate(summary_report['recommendations']):\n",
        "    report_data_list.append([f'Recommendation #{i+1}', rec_text])\n",
        "\n",
        "# e) Unroll details for the BEST algorithm\n",
        "for key, value in summary_report['best_algorithm_details'].items():\n",
        "    if key == 'Algorithm': continue # Skip redundant name\n",
        "    descriptive_key = f\"Best Algo ({best_algo_name}) - {key}\"\n",
        "    formatted_value = f\"{value:g}\" if isinstance(value, float) else value\n",
        "    report_data_list.append([descriptive_key, formatted_value])\n",
        "\n",
        "# f) Unroll details for the WORST algorithm\n",
        "for key, value in summary_report['worst_algorithm_details'].items():\n",
        "    if key == 'Algorithm': continue # Skip redundant name\n",
        "    descriptive_key = f\"Worst Algo ({worst_algo_name}) - {key}\"\n",
        "    formatted_value = f\"{value:g}\" if isinstance(value, float) else value\n",
        "    report_data_list.append([descriptive_key, formatted_value])\n",
        "\n",
        "\n",
        "# 4. Create and display the DataFrame\n",
        "summary_df = pd.DataFrame(report_data_list, columns=['Metric', 'Value'])\n",
        "summary_df.set_index('Metric', inplace=True)\n",
        "display(summary_df)\n",
        "\n",
        "\n",
        "# --- 2. Handle File Saving Operations based on SAVING_FLAG ---\n",
        "\n",
        "if not SAVING_FLAG:\n",
        "    # If not saving, just print a confirmation that visuals were displayed.\n",
        "    print(\"\\n[Info] SAVING_FLAG is set to False. All results and charts are displayed above but not saved to disk.\")\n",
        "\n",
        "else:\n",
        "    # If saving is enabled, proceed with all file I/O operations.\n",
        "    print(f\"\\n[Info] SAVING_FLAG is True. Saving all reports to directory: '{DEFAULT_REPORT_DIR}'\")\n",
        "\n",
        "    # The directory is already created by the charting functions, so we just confirm.\n",
        "    os.makedirs(DEFAULT_REPORT_DIR, exist_ok=True)\n",
        "\n",
        "    # a) Save main DataFrames as CSV files\n",
        "    results_df.to_csv(os.path.join(DEFAULT_REPORT_DIR, \"01_full_benchmark_summary.csv\"))\n",
        "    comparison_df.to_csv(os.path.join(DEFAULT_REPORT_DIR, \"02_comparison_vs_best.csv\"))\n",
        "    print(\"  > Saved main DataFrames to CSV.\")\n",
        "\n",
        "    # b) Save raw results dictionaries as JSON files\n",
        "    with open(os.path.join(DEFAULT_REPORT_DIR, \"03_benchmark_suite_raw_data.json\"), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(benchmark_results, f, indent=4)\n",
        "    print(\"  > Saved raw benchmark data to JSON.\")\n",
        "\n",
        "    # c) Save the comprehensive summary report\n",
        "    print(\"\\n[Info] Saving comprehensive summary report to JSON file...\")\n",
        "    try:\n",
        "        with open(os.path.join(DEFAULT_REPORT_DIR, \"comprehensive_summary_report.json\"), \"w\", encoding='utf-8') as f:\n",
        "            json.dump(summary_report, f, indent=4, ensure_ascii=False)\n",
        "        print(\"  > Report saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  > Error saving summary report: {e}\")\n",
        "\n",
        "    # d) Create a ZIP archive of all generated reports\n",
        "    print(\"  > Creating ZIP archive of all reports...\")\n",
        "    try:\n",
        "        shutil.make_archive(DEFAULT_REPORT_DIR, 'zip', root_dir=DEFAULT_REPORT_DIR)\n",
        "        print(f\"  > Successfully created archive: '{DEFAULT_REPORT_DIR}.zip'\")\n",
        "    except Exception as e:\n",
        "        print(f\"  > Error creating archive: {e}\")\n",
        "\n",
        "# --- Final Confirmation Message ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\\033[1mANALYSIS AND REPORTING COMPLETE\\033[0m\")\n",
        "if SAVING_FLAG:\n",
        "    print(f\"All reports have been saved in the '{DEFAULT_REPORT_DIR}' directory and compressed into '{DEFAULT_REPORT_DIR}.zip'.\")\n",
        "else:\n",
        "    print(\"Analysis results were displayed above. No files were saved.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "PGKGz7WiITkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main body: ANALYSIS OF EXTERNAL SOURCE FILES"
      ],
      "metadata": {
        "id": "gkGVzYWkgjdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*5 + \"\\033[1mANALYSIS OF EXTERNAL SOURCE FILES (LLVM, PTX, Python)\\033[0m\")\n",
        "\n",
        "detected_arch = platform.machine().lower()\n",
        "analyzer = EnhancedCostAnalyzer(arch=detected_arch, profile=\"RESEARCH\")\n",
        "profile_info = analyzer.composite_calculator.get_profile_info()\n",
        "\n",
        "if not os.path.isdir(DEFAULT_EXAMPLES_PATH):\n",
        "    print(f\"\\n[Info] Directory '{DEFAULT_EXAMPLES_PATH}' not found. Skipping analysis of external files.\")\n",
        "else:\n",
        "    # --- Step 1: Collect all raw results from all files and functions ---\n",
        "    all_individual_results = []\n",
        "\n",
        "    # Define the file types we want to analyze and the function to use for each.\n",
        "    file_types_to_analyze = {\n",
        "        'Python': {\n",
        "            'extension': 'py',\n",
        "            'analysis_func': analyzer.analyze_py_file # This must be defined in your analyzer class\n",
        "        },\n",
        "        'LLVM IR': {\n",
        "            'extension': 'll',\n",
        "            'analysis_func': analyzer.analyze_llvm_ir\n",
        "        },\n",
        "        'PTX GPU': {\n",
        "            'extension': 'ptx',\n",
        "            'analysis_func': analyzer.analyze_ptx\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n[Info] Found directory '{DEFAULT_EXAMPLES_PATH}'. Searching for compatible files...\")\n",
        "\n",
        "    # Loop through our defined file types and find all matching files.\n",
        "    for file_type, config in file_types_to_analyze.items():\n",
        "        search_pattern = os.path.join(DEFAULT_EXAMPLES_PATH, f\"**/*.{config['extension']}\")\n",
        "        found_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "        for file_path in found_files:\n",
        "            print(f\"  > Analyzing {file_type} file: {file_path}\")\n",
        "\n",
        "            # Call the appropriate analysis function\n",
        "            results_from_file = config['analysis_func'](file_path)\n",
        "\n",
        "            # The result can be a list (for .py) or a single dict (for others)\n",
        "            # To handle both consistently, we'll ensure we have a list.\n",
        "            if not isinstance(results_from_file, list):\n",
        "                # For non-python files, wrap the single result dict in a list\n",
        "                single_result = results_from_file\n",
        "                single_result['Source File'] = os.path.basename(file_path)\n",
        "                single_result['Function Name'] = '-' # No specific function name\n",
        "                single_result['File Type'] = file_type\n",
        "                results_from_file = [single_result]\n",
        "\n",
        "            # Add the File Type to results from Python files\n",
        "            if file_type == 'Python':\n",
        "                for res in results_from_file:\n",
        "                    res['File Type'] = file_type\n",
        "\n",
        "            # Use extend to add all items from the list to our main results\n",
        "            all_individual_results.extend(results_from_file)\n",
        "\n",
        "    # --- Step 2: Aggregate the results by source file ---\n",
        "    aggregated_results = {}\n",
        "\n",
        "    for result in all_individual_results:\n",
        "        file_name = result['Source File']\n",
        "\n",
        "        if file_name not in aggregated_results:\n",
        "            # Initialize the entry for this file\n",
        "            aggregated_results[file_name] = {\n",
        "                'Source File': file_name,\n",
        "                'File Type': result.get('File Type', 'Unknown'),\n",
        "                'Function Name': [], # We will collect function names in a list\n",
        "                'CU': 0, 'EU': 0, 'CO2': 0, '$': 0\n",
        "            }\n",
        "\n",
        "        # Aggregate raw numeric metrics\n",
        "        for metric in ['CU', 'EU', 'CO2', '$']:\n",
        "            aggregated_results[file_name][metric] += result.get(metric, 0)\n",
        "\n",
        "        # Collect function names, avoiding duplicates and placeholders\n",
        "        func_name = result.get('Function Name')\n",
        "        if func_name and func_name not in aggregated_results[file_name]['Function Name']:\n",
        "            aggregated_results[file_name]['Function Name'].append(func_name)\n",
        "\n",
        "    # --- Step 3: Finalize the aggregated data for display ---\n",
        "    final_aggregated_list = []\n",
        "    for file_name, data in aggregated_results.items():\n",
        "        # Join the list of function names into a single readable string\n",
        "        if data['Function Name']:\n",
        "            data['Function Name'] = ', '.join(sorted(data['Function Name']))\n",
        "        else:\n",
        "            # Handle files like .ll or .ptx that have no function names\n",
        "            data['Function Name'] = '-'\n",
        "\n",
        "        # If the file had an error or no functions, its raw metrics will be 0.\n",
        "        # We need to handle this to avoid division by zero in score calculation.\n",
        "        if data['CU'] > 0:\n",
        "            # Recalculate the composite score based on the SUMMED raw metrics\n",
        "            final_data_with_score = analyzer.composite_calculator.calculate_composite_score(data)\n",
        "            final_aggregated_list.append(final_data_with_score)\n",
        "        else:\n",
        "            # For files with no analyzable content, just add them with 0 scores\n",
        "            data['COMPOSITE_SCORE'] = data.get('COMPOSITE_SCORE', 0)\n",
        "            data['SCORE_GRADE'] = data.get('SCORE_GRADE', 'N/A')\n",
        "            final_aggregated_list.append(data)\n",
        "\n",
        "    # --- Step 4: Create and display the final aggregated DataFrame ---\n",
        "    if not final_aggregated_list:\n",
        "        print(\"\\n[Info] No compatible files (.py, .ll, .ptx) found in the 'examples' directory.\")\n",
        "    else:\n",
        "        external_df = pd.DataFrame(final_aggregated_list)\n",
        "\n",
        "        # Define the columns for the final output table\n",
        "        display_columns = [\n",
        "            'Source File', 'File Type', 'Function Name',\n",
        "            'COMPOSITE_SCORE', 'SCORE_GRADE', 'CU', 'EU', 'CO2', '$'\n",
        "        ]\n",
        "        # Ensure we only try to access columns that actually exist\n",
        "        existing_cols = [col for col in display_columns if col in external_df.columns]\n",
        "        external_df = external_df[existing_cols]\n",
        "\n",
        "        # Sort the results and set the index for a clean look\n",
        "        external_df.sort_values(by='COMPOSITE_SCORE', ascending=False, inplace=True)\n",
        "        external_df.set_index('Source File', inplace=True)\n",
        "\n",
        "        print(\"\\n[Analysis] Aggregated Assessment of External Files:\")\n",
        "        display(external_df)"
      ],
      "metadata": {
        "id": "846xfBT5b61l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92b17e75-8638-402c-d376-883cd73a3364"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "######################################################################################################################################################\n",
            "\n",
            "\t\t\t\t\t\u001b[1mANALYSIS OF EXTERNAL SOURCE FILES (LLVM, PTX, Python)\u001b[0m\n",
            "\n",
            "[Info] Found directory './examples'. Searching for compatible files...\n",
            "  > Analyzing Python file: ./examples/complexity_cost_profiler_en.py\n",
            "    > Found 'create_benchmark_summary_chart' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'create_enhanced_comparison_chart' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'generate_recommendations' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'main' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'save_enhanced_csv' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator.__init__' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator._get_efficiency_rating' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator._get_profile_description' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator._get_score_grade' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator._z_to_percentile' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator.calculate_composite_score' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator.get_profile_info' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator.normalize_metric' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'CompositeScoreCalculator.update_reference_values' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.__init__' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer._calculate_benchmark_stats' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.analyze_function' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.analyze_llvm_ir' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.analyze_ptx' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.benchmark_suite' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.compare_functions' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'EnhancedCostAnalyzer.fetch_carbon_intensity' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'InstructionCostModel.__init__' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'InstructionCostModel._get_bytecode_mapping' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'InstructionCostModel._get_default_cost_model' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'InstructionCostModel._load_weights' in complexity_cost_profiler_en.py, analyzing...\n",
            "    > Found 'InstructionCostModel.get_cost' in complexity_cost_profiler_en.py, analyzing...\n",
            "  > Analyzing Python file: ./examples/complexity_cost_profiler.py\n",
            "    > Found 'CostAnalyzer.__init__' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'CostAnalyzer.analyze_function' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'CostAnalyzer.analyze_llvm_ir' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'CostAnalyzer.analyze_ptx' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'CostAnalyzer.compare_functions' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'CostAnalyzer.fetch_carbon_intensity' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'InstructionCostModel.__init__' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'InstructionCostModel._load_weights' in complexity_cost_profiler.py, analyzing...\n",
            "    > Found 'InstructionCostModel.get_cost' in complexity_cost_profiler.py, analyzing...\n",
            "  > Analyzing Python file: ./examples/ds_tool.py\n",
            "    > Found 'CorrelationConfig.__copy__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__deepcopy__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__delattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__eq__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__getattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__getstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__init__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__iter__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__pretty__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__replace__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__repr_args__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__repr_name__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__repr_recursion__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__repr_str__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__rich_repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__setattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__setstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.__str__' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig._calculate_keys' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig._copy_and_set_values' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig._iter' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig._setattr_handler' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.copy' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.dict' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.json' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.model_copy' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.model_dump' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.model_dump_json' in ds_tool.py, analyzing...\n",
            "    > Found 'CorrelationConfig.model_post_init' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.__init__' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.add_missing_value_features' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.calculate_entropy' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.calculate_kl_divergence' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.category_stats' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.chatterjee_correlation' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.check_NINF' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.compute_metrics' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.corr_matrix' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.describe_categorical' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.describe_numeric' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.df_stats' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.evaluate_classification' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.function_list' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.generate_alphanum_codes' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.generate_distribution' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.generate_distribution_from_metrics' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.grubbs_test' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.labeling' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.min_max_scale' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.plot_confusion_matrix' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.read_dataframes_from_zip' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.remove_outliers_iqr' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.save_dataframes_to_zip' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.sparse_calc' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.stat_normal_testing' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.test_stationarity' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.trials_res_df' in ds_tool.py, analyzing...\n",
            "    > Found 'DSTools.validate_moments' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__copy__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__deepcopy__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__delattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__eq__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__getattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__getstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__init__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__iter__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__pretty__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__replace__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__repr_args__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__repr_name__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__repr_recursion__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__repr_str__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__rich_repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__setattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__setstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.__str__' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig._calculate_keys' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig._copy_and_set_values' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig._iter' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig._setattr_handler' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.copy' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.dict' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.json' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.model_copy' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.model_dump' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.model_dump_json' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.model_post_init' in ds_tool.py, analyzing...\n",
            "    > Found 'DistributionConfig.validate_max_greater_than_min' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__copy__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__deepcopy__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__delattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__eq__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__getattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__getstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__init__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__iter__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__pretty__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__replace__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__repr_args__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__repr_name__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__repr_recursion__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__repr_str__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__rich_repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__setattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__setstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.__str__' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult._calculate_keys' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult._copy_and_set_values' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult._iter' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult._setattr_handler' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.copy' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.dict' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.json' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.model_copy' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.model_dump' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.model_dump_json' in ds_tool.py, analyzing...\n",
            "    > Found 'GrubbsTestResult.model_post_init' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__copy__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__deepcopy__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__delattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__eq__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__getattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__getstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__init__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__iter__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__pretty__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__replace__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__repr_args__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__repr_name__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__repr_recursion__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__repr_str__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__rich_repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__setattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__setstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.__str__' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig._calculate_keys' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig._copy_and_set_values' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig._iter' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig._setattr_handler' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.copy' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.dict' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.json' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.model_copy' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.model_dump' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.model_dump_json' in ds_tool.py, analyzing...\n",
            "    > Found 'MetricsConfig.model_post_init' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__copy__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__deepcopy__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__delattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__eq__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__getattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__getstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__init__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__iter__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__pretty__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__replace__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__repr_args__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__repr_name__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__repr_recursion__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__repr_str__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__rich_repr__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__setattr__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__setstate__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.__str__' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig._calculate_keys' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig._copy_and_set_values' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig._iter' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig._setattr_handler' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.copy' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.dict' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.json' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.model_copy' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.model_dump' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.model_dump_json' in ds_tool.py, analyzing...\n",
            "    > Found 'OutlierConfig.model_post_init' in ds_tool.py, analyzing...\n",
            "  > Analyzing Python file: ./examples/generate_instr_models.py\n",
            "    > Found 'enrich' in generate_instr_models.py, analyzing...\n",
            "    > Found 'generate_models' in generate_instr_models.py, analyzing...\n",
            "  > Analyzing Python file: ./examples/s4_act_function.py\n",
            "    > Found 's4' in s4_act_function.py, analyzing...\n",
            "  > Analyzing Python file: ./examples/custom_imputer.py\n",
            "    > Found 'KZImputer.__getstate__' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.__init__' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.__repr__' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.__setstate__' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.__sklearn_clone__' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.__sklearn_tags__' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._check_feature_names' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._check_n_features' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._find_nan_blocks' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._get_doc_link' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._get_metadata_request' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._get_tags' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._impute_1_gap' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._impute_2_gap' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._impute_3_gap' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._impute_4_gap' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._impute_5_gap' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._impute_series' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._more_tags' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._repr_html_inner' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._repr_mimebundle_' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._validate_data' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer._validate_params' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.evaluate_metrics' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.fit' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.fit_transform' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.generate_synthetic_gaps' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.get_metadata_routing' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.get_params' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.impute_gap' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.impute_gap_old' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.set_output' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.set_params' in custom_imputer.py, analyzing...\n",
            "    > Found 'KZImputer.transform' in custom_imputer.py, analyzing...\n",
            "  > Analyzing Python file: ./examples/s3_act_function.py\n",
            "    > Found '_compute_activation' in s3_act_function.py, analyzing...\n",
            "    > Found '_compute_derivative' in s3_act_function.py, analyzing...\n",
            "    > Found 'smooth_s3_activation' in s3_act_function.py, analyzing...\n",
            "  > Analyzing LLVM IR file: ./examples/str_cat.ll\n",
            "  > Analyzing LLVM IR file: ./examples/fibonacci.ll\n",
            "  > Analyzing LLVM IR file: ./examples/file_io.ll\n",
            "  > Analyzing PTX GPU file: ./examples/matrixMul_kernel_32.ptx\n",
            "  > Analyzing PTX GPU file: ./examples/test.ptx\n",
            "\n",
            "[Analysis] Aggregated Assessment of External Files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               File Type  \\\n",
              "Source File                                \n",
              "test.ptx                         PTX GPU   \n",
              "file_io.ll                       LLVM IR   \n",
              "fibonacci.ll                     LLVM IR   \n",
              "str_cat.ll                       LLVM IR   \n",
              "s4_act_function.py                Python   \n",
              "generate_instr_models.py          Python   \n",
              "s3_act_function.py                Python   \n",
              "matrixMul_kernel_32.ptx          PTX GPU   \n",
              "complexity_cost_profiler.py       Python   \n",
              "custom_imputer.py                 Python   \n",
              "complexity_cost_profiler_en.py    Python   \n",
              "ds_tool.py                        Python   \n",
              "\n",
              "                                                                    Function Name  \\\n",
              "Source File                                                                         \n",
              "test.ptx                                                                        -   \n",
              "file_io.ll                                                                      -   \n",
              "fibonacci.ll                                                                    -   \n",
              "str_cat.ll                                                                      -   \n",
              "s4_act_function.py                                                             s4   \n",
              "generate_instr_models.py                                  enrich, generate_models   \n",
              "s3_act_function.py              _compute_activation, _compute_derivative, smoo...   \n",
              "matrixMul_kernel_32.ptx                                                         -   \n",
              "complexity_cost_profiler.py     CostAnalyzer.__init__, CostAnalyzer.analyze_fu...   \n",
              "custom_imputer.py               KZImputer.__getstate__, KZImputer.__init__, KZ...   \n",
              "complexity_cost_profiler_en.py  CompositeScoreCalculator.__init__, CompositeSc...   \n",
              "ds_tool.py                      CorrelationConfig.__copy__, CorrelationConfig....   \n",
              "\n",
              "                                COMPOSITE_SCORE SCORE_GRADE    CU      EU  \\\n",
              "Source File                                                                 \n",
              "test.ptx                                99.4093          A+    15  0.0015   \n",
              "file_io.ll                              98.2849          A+    42   0.004   \n",
              "fibonacci.ll                             96.172          A+    93  0.0083   \n",
              "str_cat.ll                              92.1819          A+   189 0.01705   \n",
              "s4_act_function.py                      89.8761           A   245 0.02121   \n",
              "generate_instr_models.py                87.9534           A   291 0.02563   \n",
              "s3_act_function.py                      87.6258           A   299 0.02627   \n",
              "matrixMul_kernel_32.ptx                 74.2815           B   612  0.0612   \n",
              "complexity_cost_profiler.py             62.6856          C+   898 0.08056   \n",
              "custom_imputer.py                       50.0176          C-  6611 0.58633   \n",
              "complexity_cost_profiler_en.py           49.524           D  6941 0.61612   \n",
              "ds_tool.py                              29.7495           F 24725 2.20735   \n",
              "\n",
              "                                    CO2        $  \n",
              "Source File                                       \n",
              "test.ptx                        0.00075  0.00015  \n",
              "file_io.ll                     0.001641  0.00042  \n",
              "fibonacci.ll                   0.002939  0.00093  \n",
              "str_cat.ll                     0.005821  0.00189  \n",
              "s4_act_function.py             0.006749 0.002448  \n",
              "generate_instr_models.py       0.008528  0.00291  \n",
              "s3_act_function.py             0.008592 0.002986  \n",
              "matrixMul_kernel_32.ptx          0.0306  0.00612  \n",
              "complexity_cost_profiler.py    0.028342 0.008977  \n",
              "custom_imputer.py              0.196669 0.066143  \n",
              "complexity_cost_profiler_en.py 0.206337 0.069394  \n",
              "ds_tool.py                     0.745148 0.247147  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-229956bc-3145-4fb3-ae0b-cef27e1d3297\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Type</th>\n",
              "      <th>Function Name</th>\n",
              "      <th>COMPOSITE_SCORE</th>\n",
              "      <th>SCORE_GRADE</th>\n",
              "      <th>CU</th>\n",
              "      <th>EU</th>\n",
              "      <th>CO2</th>\n",
              "      <th>$</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Source File</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>test.ptx</th>\n",
              "      <td>PTX GPU</td>\n",
              "      <td>-</td>\n",
              "      <td>99.4093</td>\n",
              "      <td>A+</td>\n",
              "      <td>15</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.00075</td>\n",
              "      <td>0.00015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_io.ll</th>\n",
              "      <td>LLVM IR</td>\n",
              "      <td>-</td>\n",
              "      <td>98.2849</td>\n",
              "      <td>A+</td>\n",
              "      <td>42</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.001641</td>\n",
              "      <td>0.00042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fibonacci.ll</th>\n",
              "      <td>LLVM IR</td>\n",
              "      <td>-</td>\n",
              "      <td>96.172</td>\n",
              "      <td>A+</td>\n",
              "      <td>93</td>\n",
              "      <td>0.0083</td>\n",
              "      <td>0.002939</td>\n",
              "      <td>0.00093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>str_cat.ll</th>\n",
              "      <td>LLVM IR</td>\n",
              "      <td>-</td>\n",
              "      <td>92.1819</td>\n",
              "      <td>A+</td>\n",
              "      <td>189</td>\n",
              "      <td>0.01705</td>\n",
              "      <td>0.005821</td>\n",
              "      <td>0.00189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>s4_act_function.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>s4</td>\n",
              "      <td>89.8761</td>\n",
              "      <td>A</td>\n",
              "      <td>245</td>\n",
              "      <td>0.02121</td>\n",
              "      <td>0.006749</td>\n",
              "      <td>0.002448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generate_instr_models.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>enrich, generate_models</td>\n",
              "      <td>87.9534</td>\n",
              "      <td>A</td>\n",
              "      <td>291</td>\n",
              "      <td>0.02563</td>\n",
              "      <td>0.008528</td>\n",
              "      <td>0.00291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>s3_act_function.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>_compute_activation, _compute_derivative, smoo...</td>\n",
              "      <td>87.6258</td>\n",
              "      <td>A</td>\n",
              "      <td>299</td>\n",
              "      <td>0.02627</td>\n",
              "      <td>0.008592</td>\n",
              "      <td>0.002986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>matrixMul_kernel_32.ptx</th>\n",
              "      <td>PTX GPU</td>\n",
              "      <td>-</td>\n",
              "      <td>74.2815</td>\n",
              "      <td>B</td>\n",
              "      <td>612</td>\n",
              "      <td>0.0612</td>\n",
              "      <td>0.0306</td>\n",
              "      <td>0.00612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>complexity_cost_profiler.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>CostAnalyzer.__init__, CostAnalyzer.analyze_fu...</td>\n",
              "      <td>62.6856</td>\n",
              "      <td>C+</td>\n",
              "      <td>898</td>\n",
              "      <td>0.08056</td>\n",
              "      <td>0.028342</td>\n",
              "      <td>0.008977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>custom_imputer.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>KZImputer.__getstate__, KZImputer.__init__, KZ...</td>\n",
              "      <td>50.0176</td>\n",
              "      <td>C-</td>\n",
              "      <td>6611</td>\n",
              "      <td>0.58633</td>\n",
              "      <td>0.196669</td>\n",
              "      <td>0.066143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>complexity_cost_profiler_en.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>CompositeScoreCalculator.__init__, CompositeSc...</td>\n",
              "      <td>49.524</td>\n",
              "      <td>D</td>\n",
              "      <td>6941</td>\n",
              "      <td>0.61612</td>\n",
              "      <td>0.206337</td>\n",
              "      <td>0.069394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ds_tool.py</th>\n",
              "      <td>Python</td>\n",
              "      <td>CorrelationConfig.__copy__, CorrelationConfig....</td>\n",
              "      <td>29.7495</td>\n",
              "      <td>F</td>\n",
              "      <td>24725</td>\n",
              "      <td>2.20735</td>\n",
              "      <td>0.745148</td>\n",
              "      <td>0.247147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229956bc-3145-4fb3-ae0b-cef27e1d3297')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-229956bc-3145-4fb3-ae0b-cef27e1d3297 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-229956bc-3145-4fb3-ae0b-cef27e1d3297');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-604cf1ea-88b1-46d4-bb83-95a27781dc9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-604cf1ea-88b1-46d4-bb83-95a27781dc9b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-604cf1ea-88b1-46d4-bb83-95a27781dc9b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "external_df",
              "summary": "{\n  \"name\": \"external_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Source File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"complexity_cost_profiler_en.py\",\n          \"custom_imputer.py\",\n          \"test.ptx\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"File Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"PTX GPU\",\n          \"LLVM IR\",\n          \"Python\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Function Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"s4\",\n          \"KZImputer.__getstate__, KZImputer.__init__, KZImputer.__repr__, KZImputer.__setstate__, KZImputer.__sklearn_clone__, KZImputer.__sklearn_tags__, KZImputer._check_feature_names, KZImputer._check_n_features, KZImputer._find_nan_blocks, KZImputer._get_doc_link, KZImputer._get_metadata_request, KZImputer._get_tags, KZImputer._impute_1_gap, KZImputer._impute_2_gap, KZImputer._impute_3_gap, KZImputer._impute_4_gap, KZImputer._impute_5_gap, KZImputer._impute_series, KZImputer._more_tags, KZImputer._repr_html_inner, KZImputer._repr_mimebundle_, KZImputer._validate_data, KZImputer._validate_params, KZImputer.evaluate_metrics, KZImputer.fit, KZImputer.fit_transform, KZImputer.generate_synthetic_gaps, KZImputer.get_metadata_routing, KZImputer.get_params, KZImputer.impute_gap, KZImputer.impute_gap_old, KZImputer.set_output, KZImputer.set_params, KZImputer.transform\",\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COMPOSITE_SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.113536016270913,\n        \"min\": 29.749547495474967,\n        \"max\": 99.40928913793643,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          49.524010240102406,\n          50.01763517635178,\n          99.40928913793643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCORE_GRADE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"A+\",\n          \"A\",\n          \"D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7165.909705090844,\n        \"min\": 15.0,\n        \"max\": 24725.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          6941.0,\n          6611.0,\n          15.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6392198329545359,\n        \"min\": 0.0015000000000000005,\n        \"max\": 2.2073500000000013,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.6161200000000002,\n          0.5863300000000007,\n          0.0015000000000000005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21530225820473997,\n        \"min\": 0.0007500000000000002,\n        \"max\": 0.7451479999999994,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.20633700000000005,\n          0.19666899999999968,\n          0.0007500000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"$\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0716322082549272,\n        \"min\": 0.00015000000000000001,\n        \"max\": 0.2471469999999997,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.06939399999999983,\n          0.06614299999999983,\n          0.00015000000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting\n",
        "if not external_df.empty:\n",
        "    print(\"\\n[Chart] Generating custom performance scatter plot...\")\n",
        "\n",
        "    scatterplot_filepath = os.path.join(DEFAULT_REPORT_DIR, \"file_performance_scatterplot.png\")\n",
        "\n",
        "    # Call the new function. You can change the y-axis metric here if you want.\n",
        "    # For example: y_axis_metric='EU'\n",
        "    create_file_performance_scatterplot(\n",
        "        data=external_df,\n",
        "        output_filepath=scatterplot_filepath,\n",
        "        y_axis_metric='CU' # This can be changed to 'EU', 'CO2', or '$'\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "id": "tSHsmACOL9pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main body: ANALYSIS OF EXTERNAL REPO (only ONE)"
      ],
      "metadata": {
        "id": "_BfiSRHcsMtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*6 + \"\\033[1mCOMPREHENSIVE REPOSITORY ANALYSIS\\033[0m\")\n",
        "\n",
        "REPO_URL = \"https://github.com/s-kav/ds_tools.git\"\n",
        "LOCAL_REPO_PATH = \"ds_tools\"\n",
        "\n",
        "if not os.path.isdir(LOCAL_REPO_PATH):\n",
        "    print(f\"[Info] Repository '{LOCAL_REPO_PATH}' not found locally. Cloning from {REPO_URL}...\")\n",
        "    !git clone {REPO_URL}\n",
        "    print(\"[Info] Cloning complete.\")\n",
        "else:\n",
        "    print(f\"[Info] Repository '{LOCAL_REPO_PATH}' already exists locally.\")\n",
        "\n",
        "# The 'detected_arch' variable must be defined from your first initialization block\n",
        "repository_df = analyze_repository(\n",
        "    repo_path=LOCAL_REPO_PATH,\n",
        "    detected_arch=detected_arch, # Pass the architecture here\n",
        "    verbose=False\n",
        ")\n",
        "repository_df.set_index('PROFILE NAME', inplace=True)\n",
        "\n",
        "if not repository_df.empty:\n",
        "    print(f\"\\n[Analysis] Aggregated assessment for repository: '{LOCAL_REPO_PATH}'\")\n",
        "    display(repository_df.style.format({\n",
        "        'COMPOSITE_SCORE': '{:.2f}',\n",
        "        'CU': '{:,.0f}',\n",
        "        'EU': '{:,.4f}',\n",
        "        'CO2': '{:,.4f}',\n",
        "        '$': '{:,.4f}',\n",
        "    }))"
      ],
      "metadata": {
        "id": "EYrUXB_XMM2s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "f8d48fe5-755b-4e61-8ea4-118633c566fa"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "######################################################################################################################################################\n",
            "\n",
            "\t\t\t\t\t\t\u001b[1mCOMPREHENSIVE REPOSITORY ANALYSIS\u001b[0m\n",
            "[Info] Repository 'ds_tools' already exists locally.\n",
            "\n",
            "[Analysis] Aggregated assessment for repository: 'ds_tools'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a5676872dd0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_ab75c\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_ab75c_level0_col0\" class=\"col_heading level0 col0\" >File Type</th>\n",
              "      <th id=\"T_ab75c_level0_col1\" class=\"col_heading level0 col1\" >Function Name</th>\n",
              "      <th id=\"T_ab75c_level0_col2\" class=\"col_heading level0 col2\" >COMPOSITE_SCORE</th>\n",
              "      <th id=\"T_ab75c_level0_col3\" class=\"col_heading level0 col3\" >SCORE_GRADE</th>\n",
              "      <th id=\"T_ab75c_level0_col4\" class=\"col_heading level0 col4\" >CU</th>\n",
              "      <th id=\"T_ab75c_level0_col5\" class=\"col_heading level0 col5\" >EU</th>\n",
              "      <th id=\"T_ab75c_level0_col6\" class=\"col_heading level0 col6\" >CO2</th>\n",
              "      <th id=\"T_ab75c_level0_col7\" class=\"col_heading level0 col7\" >$</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >PROFILE NAME</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "      <th class=\"blank col4\" >&nbsp;</th>\n",
              "      <th class=\"blank col5\" >&nbsp;</th>\n",
              "      <th class=\"blank col6\" >&nbsp;</th>\n",
              "      <th class=\"blank col7\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ab75c_level0_row0\" class=\"row_heading level0 row0\" >RESEARCH</th>\n",
              "      <td id=\"T_ab75c_row0_col0\" class=\"data row0 col0\" >Python (30)</td>\n",
              "      <td id=\"T_ab75c_row0_col1\" class=\"data row0 col1\" >272</td>\n",
              "      <td id=\"T_ab75c_row0_col2\" class=\"data row0 col2\" >22.58</td>\n",
              "      <td id=\"T_ab75c_row0_col3\" class=\"data row0 col3\" >F</td>\n",
              "      <td id=\"T_ab75c_row0_col4\" class=\"data row0 col4\" >31,540</td>\n",
              "      <td id=\"T_ab75c_row0_col5\" class=\"data row0 col5\" >2.8188</td>\n",
              "      <td id=\"T_ab75c_row0_col6\" class=\"data row0 col6\" >0.9585</td>\n",
              "      <td id=\"T_ab75c_row0_col7\" class=\"data row0 col7\" >0.3152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ab75c_level0_row1\" class=\"row_heading level0 row1\" >COMMERCIAL</th>\n",
              "      <td id=\"T_ab75c_row1_col0\" class=\"data row1 col0\" >Python (30)</td>\n",
              "      <td id=\"T_ab75c_row1_col1\" class=\"data row1 col1\" >272</td>\n",
              "      <td id=\"T_ab75c_row1_col2\" class=\"data row1 col2\" >15.19</td>\n",
              "      <td id=\"T_ab75c_row1_col3\" class=\"data row1 col3\" >F</td>\n",
              "      <td id=\"T_ab75c_row1_col4\" class=\"data row1 col4\" >31,540</td>\n",
              "      <td id=\"T_ab75c_row1_col5\" class=\"data row1 col5\" >2.8188</td>\n",
              "      <td id=\"T_ab75c_row1_col6\" class=\"data row1 col6\" >0.9585</td>\n",
              "      <td id=\"T_ab75c_row1_col7\" class=\"data row1 col7\" >0.3152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ab75c_level0_row2\" class=\"row_heading level0 row2\" >MOBILE</th>\n",
              "      <td id=\"T_ab75c_row2_col0\" class=\"data row2 col0\" >Python (30)</td>\n",
              "      <td id=\"T_ab75c_row2_col1\" class=\"data row2 col1\" >272</td>\n",
              "      <td id=\"T_ab75c_row2_col2\" class=\"data row2 col2\" >36.53</td>\n",
              "      <td id=\"T_ab75c_row2_col3\" class=\"data row2 col3\" >F</td>\n",
              "      <td id=\"T_ab75c_row2_col4\" class=\"data row2 col4\" >31,540</td>\n",
              "      <td id=\"T_ab75c_row2_col5\" class=\"data row2 col5\" >2.8188</td>\n",
              "      <td id=\"T_ab75c_row2_col6\" class=\"data row2 col6\" >0.9585</td>\n",
              "      <td id=\"T_ab75c_row2_col7\" class=\"data row2 col7\" >0.3152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ab75c_level0_row3\" class=\"row_heading level0 row3\" >HPC</th>\n",
              "      <td id=\"T_ab75c_row3_col0\" class=\"data row3 col0\" >Python (30)</td>\n",
              "      <td id=\"T_ab75c_row3_col1\" class=\"data row3 col1\" >272</td>\n",
              "      <td id=\"T_ab75c_row3_col2\" class=\"data row3 col2\" >22.17</td>\n",
              "      <td id=\"T_ab75c_row3_col3\" class=\"data row3 col3\" >F</td>\n",
              "      <td id=\"T_ab75c_row3_col4\" class=\"data row3 col4\" >31,540</td>\n",
              "      <td id=\"T_ab75c_row3_col5\" class=\"data row3 col5\" >2.8188</td>\n",
              "      <td id=\"T_ab75c_row3_col6\" class=\"data row3 col6\" >0.9585</td>\n",
              "      <td id=\"T_ab75c_row3_col7\" class=\"data row3 col7\" >0.3152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ab75c_level0_row4\" class=\"row_heading level0 row4\" >DEFAULT</th>\n",
              "      <td id=\"T_ab75c_row4_col0\" class=\"data row4 col0\" >Python (30)</td>\n",
              "      <td id=\"T_ab75c_row4_col1\" class=\"data row4 col1\" >272</td>\n",
              "      <td id=\"T_ab75c_row4_col2\" class=\"data row4 col2\" >18.99</td>\n",
              "      <td id=\"T_ab75c_row4_col3\" class=\"data row4 col3\" >F</td>\n",
              "      <td id=\"T_ab75c_row4_col4\" class=\"data row4 col4\" >31,540</td>\n",
              "      <td id=\"T_ab75c_row4_col5\" class=\"data row4 col5\" >2.8188</td>\n",
              "      <td id=\"T_ab75c_row4_col6\" class=\"data row4 col6\" >0.9585</td>\n",
              "      <td id=\"T_ab75c_row4_col7\" class=\"data row4 col7\" >0.3152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ab75c_level0_row5\" class=\"row_heading level0 row5\" >TOTAL</th>\n",
              "      <td id=\"T_ab75c_row5_col0\" class=\"data row5 col0\" >All Files (30)</td>\n",
              "      <td id=\"T_ab75c_row5_col1\" class=\"data row5 col1\" >272</td>\n",
              "      <td id=\"T_ab75c_row5_col2\" class=\"data row5 col2\" >23.09</td>\n",
              "      <td id=\"T_ab75c_row5_col3\" class=\"data row5 col3\" >F</td>\n",
              "      <td id=\"T_ab75c_row5_col4\" class=\"data row5 col4\" >31,540</td>\n",
              "      <td id=\"T_ab75c_row5_col5\" class=\"data row5 col5\" >2.8188</td>\n",
              "      <td id=\"T_ab75c_row5_col6\" class=\"data row5 col6\" >0.9585</td>\n",
              "      <td id=\"T_ab75c_row5_col7\" class=\"data row5 col7\" >0.3152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting\n",
        "if not repository_df.empty:\n",
        "    print(\"\\n[Chart] Generating custom performance scatter plot...\")\n",
        "\n",
        "    scatterplot_filepath = os.path.join(DEFAULT_REPORT_DIR, \"repository_performance_scatterplot.png\")\n",
        "\n",
        "    # Call the new function. You can change the y-axis metric here if you want.\n",
        "    # For example: y_axis_metric='EU'\n",
        "    create_file_performance_scatterplot(\n",
        "        data=repository_df,\n",
        "        output_filepath=scatterplot_filepath,\n",
        "        y_axis_metric='CU' # This can be changed to 'EU', 'CO2', or '$'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6pge3Kon7tW",
        "outputId": "de521834-4344-4db8-9fae-e982e60d2509"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Chart] Generating custom performance scatter plot...\n",
            "[Chart Info] Displaying top 6 files sorted by COMPOSITE_SCORE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main body: ANALYSIS OF EXTERNAL REPOS"
      ],
      "metadata": {
        "id": "cTzFcpyAvpEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\"*2 + '#'*150 + \"\\n\")\n",
        "print(\"\\t\"*6 + \"\\033[1mCOMPREHENSIVE REPOSITORY ANALYSIS\\033[0m\")\n",
        "\n",
        "# 1.  URL- \n",
        "REPO_URLS = [\n",
        "    \"https://github.com/s-kav/ds_tools.git\",\n",
        "    \"https://github.com/s-kav/kz_data_imputation.git\",\n",
        "    \"https://github.com/s-kav/s3_s4_activation_function.git\",\n",
        "    \"https://github.com/egorsmkv/radtts-uk-vocos-demo.git\",\n",
        "    \"https://github.com/PINTO0309/yolov9_wholebody34_heatmap_vis.git\",\n",
        "    \"https://github.com/MaAI-Kyoto/MaAI.git\",\n",
        "    \"https://github.com/TheAlgorithms/Python.git\",\n",
        "    \"https://github.com/tweepy/tweepy.git\",\n",
        "    \"https://github.com/lincolnloop/python-qrcode.git\",\n",
        "    \"https://github.com/prompt-toolkit/python-prompt-toolkit.git\"\n",
        "]\n",
        "detected_arch = platform.machine().lower()\n",
        "all_repo_data = {}\n",
        "# Analyze each repository and store its data\n",
        "for repo_url in REPO_URLS:\n",
        "    local_repo_path = repo_url.split('/')[-1].replace('.git', '')\n",
        "\n",
        "    if not os.path.isdir(local_repo_path):\n",
        "        subprocess.run(['git', 'clone', repo_url], capture_output=True, text=True)\n",
        "\n",
        "    repository_df = analyze_repository(\n",
        "        repo_path=local_repo_path,\n",
        "        detected_arch=detected_arch,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    if not repository_df.empty:\n",
        "        repository_df.set_index('PROFILE NAME', inplace=True)\n",
        "        all_repo_data[local_repo_path] = repository_df # Store the result\n",
        "\n",
        "        print(f\"\\n[Analysis] Aggregated assessment for repository: '{local_repo_path}'\")\n",
        "        display(repository_df.style.format({\n",
        "            'COMPOSITE_SCORE': '{:.2f}',\n",
        "            'CU': '{:,.0f}',\n",
        "            'EU': '{:,.4f}',\n",
        "            'CO2': '{:,.4f}',\n",
        "            '$': '{:,.4f}',\n",
        "        }))"
      ],
      "metadata": {
        "id": "YbxxJ3bJvrgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_URLS = [\n",
        "    \"https://github.com/s-kav/ds_tools.git\",\n",
        "    \"https://github.com/s-kav/kz_data_imputation.git\",\n",
        "    \"https://github.com/s-kav/s3_s4_activation_function.git\",\n",
        "    \"https://github.com/egorsmkv/radtts-uk-vocos-demo.git\",\n",
        "    \"https://github.com/PINTO0309/yolov9_wholebody34_heatmap_vis.git\",\n",
        "    \"https://github.com/MaAI-Kyoto/MaAI.git\",\n",
        "    \"https://github.com/TheAlgorithms/Python.git\",\n",
        "    \"https://github.com/tweepy/tweepy.git\",\n",
        "    \"https://github.com/lincolnloop/python-qrcode.git\"\n",
        "]\n",
        "for repo_url in REPO_URLS:\n",
        "  local_repo_path = repo_url.split('/')[-1].replace('.git', '')\n",
        "  shutil.rmtree('/content/' + local_repo_path)"
      ],
      "metadata": {
        "id": "6TxsYgSIvrkH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Plotting section: generates ONE summary chart after all analyses are done ---\n",
        "if all_repo_data:\n",
        "    print(\"\\n[Chart] Generating summary comparison chart for all repositories...\")\n",
        "\n",
        "    summary_chart_filepath = os.path.join(DEFAULT_REPORT_DIR, \"repository_comparison_summary.png\")\n",
        "\n",
        "    # Call the new function to create the comparison chart.\n",
        "    # You can change the profile to plot, e.g., \"RESEARCH\", \"COMMERCIAL\", etc.\n",
        "    create_repository_comparison_chart(\n",
        "        repo_data=all_repo_data,\n",
        "        output_filepath=summary_chart_filepath,\n",
        "        profile_to_plot=\"TOTAL\" # This determines which row to use from each DataFrame\n",
        "    )\n",
        "else:\n",
        "    print(\"\\n[Info] No data was collected from repositories, skipping chart generation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ9RhRgVA0-j",
        "outputId": "75e4804a-a60b-4c20-8e35-6352d92fc7b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Chart] Generating summary comparison chart for all repositories...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# end"
      ],
      "metadata": {
        "id": "u7aS9LY9tLW3"
      }
    }
  ]
}